{"posts": [{"thread": {"uuid": "d0e0d7d717cf38dcbdfe04d23729684050ea158d", "url": "http://omgili.com/ri/.wHSUbtEfZShuqU8OSon1xB4C1imBQp0uCXKWA0r6sPGRKYrsZ3o.EBYf2_VKU62KBjD.LyQraV63cFLfJARXzoGrfzNgBesvUWlEuDYe90-", "site_full": "www.broadinstitute.org", "site": "broadinstitute.org", "site_section": "https://www.broadinstitute.org/rss.xml", "site_categories": ["health"], "section_title": "Broad Institute", "title": "New CRISPR tool targets RNA in mammalian cells", "title_full": "New CRISPR tool targets RNA in mammalian cells", "published": "2017-10-04T17:02:00.000+03:00", "replies_count": 0, "participants_count": 1, "site_type": "news", "country": "US", "spam_score": 0.0, "main_image": "", "performance_score": 0, "domain_rank": 45479, "social": {"facebook": {"likes": 0, "comments": 0, "shares": 0}, "gplus": {"shares": 0}, "pinterest": {"shares": 0}, "linkedin": {"shares": 0}, "stumbledupon": {"shares": 0}, "vk": {"shares": 0}}}, "uuid": "d0e0d7d717cf38dcbdfe04d23729684050ea158d", "url": "http://omgili.com/ri/.wHSUbtEfZShuqU8OSon1xB4C1imBQp0uCXKWA0r6sPGRKYrsZ3o.EBYf2_VKU62KBjD.LyQraV63cFLfJARXzoGrfzNgBesvUWlEuDYe90-", "ord_in_thread": 0, "author": "veronica@broadinstitute.org", "published": "2017-10-04T17:02:00.000+03:00", "title": "New CRISPR tool targets RNA in mammalian cells", "text": "New CRISPR tool targets RNA in mammalian cells Credit : Image courtesy of Lauren Solomon, Broad Communications. By Veronica Meade-Kelly \nResearchers use CRISPR-Cas13 to cut and bind RNA, expanding the genome-editing toolbox. \nResearchers from the Broad Institute of MIT and Harvard have shown that a CRISPR-based editing system can cut and bind RNA in mammalian cells. In a paper out this week in Nature , the team used CRISPR-Cas13, which the researchers had helped discover , to both reduce RNA levels and \u201ctag\u201d RNAs in order to view and track them within cells. The researchers previously used CRISPR-Cas13 to target RNA in bacterial cells, but proving that the system could work safely and effectively in mammalian cells was a critical step toward using the system to study human biology and disease. \nHaving this sort of programmable tool for modulating RNA in mammalian cells creates new opportunities for learning how cells function and, potentially, for designing safer therapeutics. Unlike editing DNA, which makes permanent changes to the genome of a cell, targeting RNA could enable researchers to make temporary changes that alter the amount of protein produced by a gene rather than stopping production entirely. \n\u201cEven though we have good tools to delete genes, they still have many limitations that make the study of gene function difficult,\u201d explains co-first author Omar Abudayyeh, who is a graduate student in the lab of Broad core member and MIT associate professor Feng Zhang . \u201cCas13 allows you to bring down gene expression levels without completely eliminating them, which is useful for studying genes and may offer a less toxic therapeutic approach to correcting genetic diseases.\u201d \nThe team, led by scientists from Zhang\u2019s lab , tested Cas13 enzymes from fifteen different microbes to find the one, from Leptotrichia wadei (LwaCas13a), that was best-suited for the task. Using LwaCas13a enabled them to cut specific sites in targeted RNA with greater specificity than the current RNA-knockdown tool-of-choice, RNA-interference (RNAi). Although RNAi can be a useful tool, it often leads to unwanted off-target effects, making experiments difficult to interpret. Such off-target effects were significantly reduced with Cas13. \nZhang\u2019s team also demonstrated that a so-called \u201cdead\u201d variant of Cas13 that binds RNA but doesn\u2019t cut it can be combined with bright fluorescent \u201ctags\u201d to visually track target RNA as it moves within the cell. \n\u201cOur engineering of Cas13 here to bind and image transcripts shows the promise of this platform for the development of a broader set of tools to monitor and manipulate RNA,\u201d adds co-first author Jonathan Gootenberg, who is also a graduate student in Zhang\u2019s lab as well as the lab of Broad core member Aviv Regev. \nThe researchers note that CRISPR-Cas13\u2019s native ability to bind RNA also makes it easier to use than other technologies, which currently require researchers to modify the genome of an organism in order to create a binding site. These features could make CRISPR-Cas13 a key addition to biologists\u2019 toolbox for studying gene function; researchers can obtain CRISPR-Cas13 tools via the non-profit plasmid repository Addgene . \n\nResearchers who worked on the study include Patrick Essletzbichler, Shuo Han, Julia Joung, Joseph Belanto, Vanessa Verdine, David Cox, Max Kellner, Aviv Regev, Eric Lander, Daniel Voytas, and Alice Ting. \nSupport for the study came from the National Institutes of Health through the National Institute of Mental Health; Howard Hughes Medical Institute; New York Stem Cell Foundation; Simons Foundation; Paul G. Allen Family Foundation; the Vallee Foundation; James and Patricia Poitras, Robert Metcalfe, and David Cheng. Additional support was provided by the Department of Energy Computational Science Graduate Fellowship; Paul and Daisy Soros Fellowship; and National Defense Science and Engineering Fellowship. Paper(s) cited: \nAbudayyeh O, Gootenberg, J et al . RNA targeting with CRISPR-Cas13 . Nature . Online October 4, 2017. DOI: 10.1038/nature24049 Links", "highlightText": "", "highlightTitle": "", "language": "english", "external_links": [], "entities": {"persons": [{"name": "lauren solomon", "sentiment": "negative"}, {"name": "alice ting", "sentiment": "none"}, {"name": "james", "sentiment": "none"}, {"name": "jonathan gootenberg", "sentiment": "none"}, {"name": "julia joung", "sentiment": "none"}, {"name": "vanessa verdine", "sentiment": "none"}, {"name": "david cheng", "sentiment": "none"}, {"name": "zhang", "sentiment": "none"}, {"name": "patrick essletzbichler", "sentiment": "none"}, {"name": "max kellner", "sentiment": "none"}, {"name": "paul g. allen", "sentiment": "none"}, {"name": "paul", "sentiment": "none"}, {"name": "robert metcalfe", "sentiment": "none"}, {"name": "eric lander", "sentiment": "none"}, {"name": "omar abudayyeh", "sentiment": "none"}, {"name": "feng zhang", "sentiment": "none"}, {"name": "veronica meade-kelly", "sentiment": "none"}, {"name": "patricia poitras", "sentiment": "none"}, {"name": "shuo han", "sentiment": "none"}, {"name": "daniel voytas", "sentiment": "none"}, {"name": "joseph belanto", "sentiment": "none"}, {"name": "david cox", "sentiment": "none"}, {"name": "aviv regev", "sentiment": "none"}], "organizations": [{"name": "broad comm", "sentiment": "negative"}, {"name": "new york stem cell foundation", "sentiment": "none"}, {"name": "simons foundation", "sentiment": "none"}, {"name": "howard hughes medical institute", "sentiment": "none"}, {"name": "family foundation", "sentiment": "none"}, {"name": "vallee foundation", "sentiment": "none"}, {"name": "mit", "sentiment": "none"}, {"name": "national institute of mental health", "sentiment": "none"}, {"name": "national institutes of health", "sentiment": "none"}, {"name": "daisy soros fellowship", "sentiment": "none"}, {"name": "department of energy computational science graduate fellowship", "sentiment": "none"}, {"name": "national defense science and engineering fellowship", "sentiment": "none"}], "locations": []}, "rating": null, "crawled": "2017-10-05T00:55:11.000+03:00"}, {"thread": {"uuid": "fcb466a599e1fea6dd2974c039647ed53cfeecba", "url": "http://omgili.com/ri/.wHSUbtEfZShuqU8OSon1xB4C1imBQp0uCXKWA0r6sPGRKYrsZ3o.JXduvInFj1_ZdQMKJ9Oa9xS7mlxb5DK8NqmUPnHWxwTut0Gd71C3Hx1yhrT3zm7iCYbgT28S08m", "site_full": "www.broadinstitute.org", "site": "broadinstitute.org", "site_section": "https://www.broadinstitute.org/rss.xml", "site_categories": ["health"], "section_title": "Broad Institute", "title": "A new CRISPR-engineered cancer model to test therapeutics", "title_full": "A new CRISPR-engineered cancer model to test therapeutics", "published": "2017-10-05T19:15:00.000+03:00", "replies_count": 0, "participants_count": 1, "site_type": "news", "country": "US", "spam_score": 0.0, "main_image": "", "performance_score": 0, "domain_rank": 45479, "social": {"facebook": {"likes": 0, "comments": 0, "shares": 0}, "gplus": {"shares": 0}, "pinterest": {"shares": 0}, "linkedin": {"shares": 0}, "stumbledupon": {"shares": 0}, "vk": {"shares": 0}}}, "uuid": "fcb466a599e1fea6dd2974c039647ed53cfeecba", "url": "http://omgili.com/ri/.wHSUbtEfZShuqU8OSon1xB4C1imBQp0uCXKWA0r6sPGRKYrsZ3o.JXduvInFj1_ZdQMKJ9Oa9xS7mlxb5DK8NqmUPnHWxwTut0Gd71C3Hx1yhrT3zm7iCYbgT28S08m", "ord_in_thread": 0, "author": "kzusi@broadinstitute.org", "published": "2017-10-05T19:15:00.000+03:00", "title": "A new CRISPR-engineered cancer model to test therapeutics", "text": "A new CRISPR-engineered cancer model to test therapeutics Credit : Susanna M. Hamilton, Broad Communications By Karen Zusi \nNew technique for modeling human leukemia in mice may aid drug discovery, clinical trials \nOne major challenge in cancer research is developing robust pre-clinical models for new therapies, ones that will accurately reflect a human response to a novel compound. All too often, a potential treatment that initially looked promising in cells or animal models will not have the same effects in a human cancer patient. \nGiven the enormous costs of clinical trials, researchers need pre-clinical models that accurately reflect human disease genetics and reliably predict which drugs have the most potential to succeed in patients. In Cell Stem Cell this week, a team led by Zuzana Tothova , a postdoctoral scholar at   Harvard and instructor in medicine at Dana-Farber Cancer Institute (DFCI), and Broad institute member Ben Ebert , also a professor of medicine at Harvard Medical School and chair of medical oncology at DFCI, describe a new approach that has the potential to make this leap. \nUsing multiplex CRISPR-Cas9 editing of human hematopoietic, or blood-forming, stem cells followed by transplantation in mice, the team designed customized mouse models for the progression of leukemia. In a number of different experiments, the animal models successfully reflected human responses to a therapeutic agent commonly used to treat blood cancers. \u201cWith our models, we can really test \u2014 in a very controlled fashion, in the right setting, and using the right cells \u2014 the genetic predictors of response to specific agents,\u201d said Tothova. Learning from human genetics \nThe research team started by examining large-scale sequencing data from Ebert\u2019s lab and The Cancer Genome Atlas to determine which combinations of mutations occur most commonly in myelodysplastic syndrome (MDS) and acute myeloid leukemia (AML), blood cancers in which the bone marrow fails to produce healthy blood cells. The researchers landed on nine genes that are recurrently mutated in MDS and AML. \n\u201cWe use human genetics to teach us which combinations of mutations lead to cancer,\u201d explained Ebert. \u201cIf we have sequencing data from enough tumors, we can identify the genes that are mutated recurrently and which combinations of mutations co-occur more commonly than expected by chance.\u201d \nCurrently, many cancer models (such as cell lines) do not reflect the cancer genetics that a particular investigator would like to study, which often leaves both researchers and patients at a disadvantage. One strategy is to transplant an actual human cancer sample into a mouse, but the cancer tissue often doesn\u2019t engraft well, and researchers are only able to test against the specific combination of mutations accumulated in a given cancer sample in the first place. \nTo study these specific MDS-driving mutations in combination, the team developed a pipeline to insert them into new lab models. \n\u201cSay we\u2019re trying to develop a new drug against a particular combination of mutations, which we know about through the cancer sequencing efforts,\u201d said Tothova. \u201cYou might not have any sample available to study with that particular combination of mutations. We wanted to be able to engineer the right lesions in human cells, let them expand in mice, and generate an accurate genetic model of disease for testing new therapies. This has been a longstanding goal for cancer researchers, and for the pharmaceutical industry, for a very long time.\u201d Customizing cancer mutations with CRISPR \nTo create models with the right mutations, Tothova and her team established a customizable system to introduce the cancer-driving mutations into human hematopoietic stem cells, where MDS and AML originate. The researchers already had extensive experience working with hematopoietic stem cells and progenitor cells, largely from umbilical cord blood or adult bone marrow, and in 2014, they published a Nature Biotechnology paper in which they described using the CRISPR-Cas9 system to create similar models of mouse cancers. This time, the team was aiming to model MDS in human cells, a much more challenging goal. \nThe researchers took primary cells from healthy donors and used CRISPR-Cas9 to engineer them with a number of different mutation combinations, rather than a single alteration, in order to reflect the complexity of tumor mutations seen in patients. The combinations of mutations that the cells tolerated \u2014 those that successfully altered the genes without killing the cells \u2014 and that led to expansion over time were also the ones seen in human tumor samples. \n\u201cNobody so far has done this kind of multiplex CRISPR engineering in the actual hematopoietic stem cell compartment, adding specific mutations in combination to generate disease models,\u201d said Tothova. \nFrom there, the team injected the stem cells into the mice\u2019s circulatory systems, where a portion incorporated themselves into the bone marrow. The team monitored their progression, extracting and sequencing the human cells five months later to determine which engineered cells successfully propagated and which mutations became the most common over time in these pre-malignant and early malignant states. Testing therapeutic agents \nThe mainstay of treatment for MDS patients are hypomethylating agents called azacitidine and decitabine. Based on previous studies, the team identified specific genetic mutations that could be used to predict cancer cells\u2019 response to these compounds in humans. (For example, mutations in a gene called TET2 predict treatment success for MDS patients, while mutations in the ASXL1 gene predict resistance in the tumors.) \nWhen the researchers treated the mice with azacitidine, they found that the response in the engineered cells matched what was expected from the human data: TET2 -mutated cells responded to the drug, while ASXL1 -mutated cells were resistant to the therapy. The team also discovered that mutations in a cohesin gene, SMC3 , increased sensitivity to the drug \u2014 data that could be important to clinicians and patients whose tumors share those mutations. \n\u201cWe are able to recapitulate findings previously seen in human clinical trials, which makes us feel more confident in the power of these models,\u201d said Tothova. \u201cThe data that comes from patients reflects the most important experiment we are trying to understand.\u201d She is currently working with clinical collaborators at DFCI to extend some of these findings into clinical trials. \nThe team believes their approach to create this type of leukemia progression model for therapeutic testing can be applied to other types of cancer as well, as long as sequencing data is available to choose appropriate mutations and progenitor cells can be acquired from the desired tissue. \u201cPeople in the field are hungry for these kinds of models,\u201d said Ebert. \u201cWe are modeling the disease in the right cellular context with a genetic complexity that reflects what we see in patients. This hasn\u2019t been done before, and it could become a really beneficial tool.\u201d \nThis project was supported in part by funding from the Broad Institute\u2019s BroadIgnite program, which connects rising philanthropists to emerging scientists pursuing high-risk \u2014 and potentially high-reward \u2014 ideas. \nAdditional funding was provided by the NIH (R01HL082945, P01CA108631, 5K12CA087723-12, T32GM007753, and DK106829), the Edward P. Evans Foundation, the Gabrielle\u2019s Angel Foundation, the LLS Scholar Award, the LLS Special Fellow Award, the ASCO Young Investigator Award, and the ASH/EHA Translational Research in Hematology Award. Paper(s) cited: \nTothova Z, et al. Multiplex CRISPR/Cas9-based genome editing in human hematopoietic stem cells models clonal hematopoiesis and myeloid neoplasia . Cell Stem Cell . Online October 5, 2017. DOI: 10.1016/j.stem.2017.07.015 Related Content", "highlightText": "", "highlightTitle": "", "language": "english", "external_links": [], "entities": {"persons": [], "organizations": [], "locations": []}, "rating": null, "crawled": "2017-10-06T00:12:58.004+03:00"}, {"thread": {"uuid": "51a8d71f27ed284b4ecefa34c98ce6ade59328cd", "url": "http://omgili.com/ri/.wHSUbtEfZShuqU8OSon1xB4C1imBQp0uCXKWA0r6sM_vbKwKpCoQfeltlmDQ_qWLwsyR0lEd2Pzb9Ji5YS342oz_GS1UPbCiAVuagalrZP2.42W4oG3hQ--", "site_full": "www.broadinstitute.org", "site": "broadinstitute.org", "site_section": "https://www.broadinstitute.org/rss.xml", "site_categories": ["health"], "section_title": "Broad Institute", "title": "To cross the therapeutics finish line, we need to change the race", "title_full": "To cross the therapeutics finish line, we need to change the race", "published": "2017-10-09T18:10:00.000+03:00", "replies_count": 0, "participants_count": 1, "site_type": "news", "country": "US", "spam_score": 0.0, "main_image": "", "performance_score": 0, "domain_rank": 45479, "social": {"facebook": {"likes": 0, "comments": 0, "shares": 0}, "gplus": {"shares": 0}, "pinterest": {"shares": 0}, "linkedin": {"shares": 0}, "stumbledupon": {"shares": 0}, "vk": {"shares": 0}}}, "uuid": "51a8d71f27ed284b4ecefa34c98ce6ade59328cd", "url": "http://omgili.com/ri/.wHSUbtEfZShuqU8OSon1xB4C1imBQp0uCXKWA0r6sM_vbKwKpCoQfeltlmDQ_qWLwsyR0lEd2Pzb9Ji5YS342oz_GS1UPbCiAVuagalrZP2.42W4oG3hQ--", "ord_in_thread": 0, "author": "mnemchuk@broadinstitute.org", "published": "2017-10-09T18:10:00.000+03:00", "title": "To cross the therapeutics finish line, we need to change the race", "text": "To cross the therapeutics finish line, we need to change the race By Todd Golub, Chief Scientific Officer \nScientific discoveries are outstripping our ability to convert them into medicines. Here's how we are tackling the challenge. \nOver the last 15 years, it has finally become possible to systematically discover the genes that play crucial roles across a range of human diseases \u2014 from cancer, to autoimmune disease, heart disease, and even schizophrenia. The pace of discovery is accelerating due to progress in researchers\u2019 ability to find genetic variants that predispose to diseases, edit the genome in living cells, and create animal models that more closely mimic human biology. Together, the insights that are emerging are pointing us to the root causes of disease. \nBut there\u2019s a problem: Scientific discoveries are outstripping our ability to convert them into medicines for patients. \nThe pharmaceutical industry is a powerful engine for therapeutic discovery. But its efforts have largely been optimized around certain types of targets that have previously been shown to be tractable \u2014 for example, kinases and other enzymes. Other targets (such as transcription factors and protein-protein interactions), which lack a clear path, are often considered too risky or too time-consuming to tackle. Yet, these unprecedented target types are often key drivers in many diseases. \nMoreover, even for readily \u201cdruggable\u201d targets, we often don\u2019t know how to design clinical development strategies grounded in the molecular basis of disease \u2014 for example, how to use genetics to identify the right patients in whom to test a drug, or how to identify biomarkers to monitor efficacy rapidly, especially for prevention trials. \nTo speed the development of therapies for patients, both academia and industry \u2014 across pharma and finance \u2014 need to change the way we think and work together. \nThe answers do not lie in academia or industry alone. Only by collaborating more closely with all private sector partners will we uncover them. \nAcademia and industry share by the goal of improving the health of patients \u2014 but bring complementary skills and perspectives. In academia, our contributions often come through earlier-stage discovery and innovation \u2014 grounded in deep biological knowledge and unconstrained by the need to make a profit for investors. The biopharmaceutical industry contributes deep expertise in drug-hunting, larger teams, and the ability to run major clinical trials. \nThe model has been effective \u2014 but it\u2019s becoming clear there\u2019s a missing piece. \nInteractions between academia and industry often resemble a relay race \u2014 in which runners share the baton only for a brief hand-off. \nBut for some biomedical problems, it\u2019s important to draw simultaneously on the skills of academia and industry. We need to explore appropriate ways in which the two sides can engage in more extended exchange of knowledge, ideas, and methods. \nCloser collaboration requires launching therapeutic partnerships between academia and industry that begin earlier and extend later. Industry\u2019s insights into clinical development should infuse even early-stage academic drug discovery projects. Likewise, academic science should accompany new drugs all the way into the clinic (for example, to maximally learn from clinical trials). \nThe focus should be on maximizing understanding \u2014 to maximize the probability that new therapies will be effective. \nTo be most impactful, academia-industry partnerships should: Aim to impact human health by breaking new ground, rather than making only incremental progress, Begin with the assumption that drug development should be grounded in the biological basis of disease, and Commit to openly sharing biological knowledge with the scientific community, while protecting intellectual property around potential therapeutic products \u2014 without which investors will never fund the clinical trials needed to prove efficacy. \nAcademic institutions should select industry partners carefully \u2014 and vice versa . These relationships should be built on shared values and complementary skills, and be held to high ethical standards. \nImportantly, partnerships need to respect the fact that the public and private sectors have different missions, obligations, and responsibilities. Academia cannot allow itself to be driven by dreams of revenues: it must prioritize public benefit. And, industry cannot drift too far into basic research: it has a duty to earn a return on investment for its shareholders. Yet, there is increasingly an appropriate zone of overlap. \nAt the   Harvard, we have chosen to take on research that is important from a patient perspective even when commercial appeal is limited. We try to tackle scientifically hard problems (such as targets that are unprecedented or thought to be undruggable) and to work on diseases of both the developed and developing world (including those often considered unprofitable, such as malaria or tuberculosis). \nWe seek partners from the private sector that share our scientific vision, respect our distinct missions, and are prepared to make the sustained scientific and funding commitments needed for high-risk, high-reward therapeutics research. \nNone of this is easy. More often than not, even the very best projects will fail to lead to successful therapeutics.", "highlightText": "", "highlightTitle": "", "language": "english", "external_links": [], "entities": {"persons": [{"name": "todd golub", "sentiment": "neutral"}], "organizations": [{"name": "harvard", "sentiment": "none"}], "locations": []}, "rating": null, "crawled": "2017-10-09T19:10:09.041+03:00"}, {"thread": {"uuid": "d3a1a1b639ad3bdcef3d381f1c5a912b322556b0", "url": "http://omgili.com/ri/.wHSUbtEfZShuqU8OSon1xB4C1imBQp0uCXKWA0r6sOSMOeSzUMMUBKQ0O1fdSVbq1AhqRXfSDBFvS9zYhv0UfnxM6hQocNHOglt.oi4mGL.fml7ErZRrlHfHfkaZmt01mYTAS_KVlW_TzSU8fqQqvtLDub7_2_s6Aixsoqud9g-", "site_full": "www.broadinstitute.org", "site": "broadinstitute.org", "site_section": "http://www.broadinstitute.org/rss.xml", "site_categories": ["health"], "section_title": "Broad Institute", "title": "Broad Institute and Deerfield Management launch innovative partnership to tackle serious unmet medical needs", "title_full": "Broad Institute and Deerfield Management launch innovative partnership to tackle serious unmet medical needs", "published": "2017-10-10T07:00:00.000+03:00", "replies_count": 0, "participants_count": 1, "site_type": "news", "country": "US", "spam_score": 0.0, "main_image": "", "performance_score": 0, "domain_rank": 45479, "social": {"facebook": {"likes": 0, "comments": 0, "shares": 0}, "gplus": {"shares": 0}, "pinterest": {"shares": 0}, "linkedin": {"shares": 0}, "stumbledupon": {"shares": 0}, "vk": {"shares": 0}}}, "uuid": "d3a1a1b639ad3bdcef3d381f1c5a912b322556b0", "url": "http://omgili.com/ri/.wHSUbtEfZShuqU8OSon1xB4C1imBQp0uCXKWA0r6sOSMOeSzUMMUBKQ0O1fdSVbq1AhqRXfSDBFvS9zYhv0UfnxM6hQocNHOglt.oi4mGL.fml7ErZRrlHfHfkaZmt01mYTAS_KVlW_TzSU8fqQqvtLDub7_2_s6Aixsoqud9g-", "ord_in_thread": 0, "author": "mnemchuk@broadinstitute.org", "published": "2017-10-10T07:00:00.000+03:00", "title": "Broad Institute and Deerfield Management launch innovative partnership to tackle serious unmet medical needs", "text": "Broad Institute and Deerfield Management launch innovative partnership to tackle serious unmet medical needs Credit : Photo by Kelly Davidson By Broad Communications New collaboration aims to advance therapeutics by rapidly funding promising, early-stage research. \nThe   Harvard and Deerfield Management announced today the launch of a first-of-its-kind research partnership, aimed at solving complex, early-stage therapeutic challenges related to serious unmet medical needs. \nThe arrangement is unique in two respects. First, a major investment firm is partnering with an academic research institution to pursue transformative, early-stage therapeutics research-- through a plan that includes funding for early-stage academic research followed by support to create new entities to develop therapies based on the most promising projects. Second, Deerfield Management will dedicate any of its profits from a successful therapeutic earned by its Healthcare Innovations Fund to its philanthropic arm, the Deerfield Foundation , which supports healthcare initiatives that benefit children and adults in underserved communities and healthcare innovation. \nIn this new partnership, Deerfield will commit more than $50 million to the advancement of therapeutic research projects at the Broad Institute over an initial period of five years. In addition, Deerfield is prepared to provide significant additional resources to advance the development of highly-promising targets generated as part of the collaboration. \n\u201cOver the last few years, Broad Institute researchers have developed a number of unprecedented biological insights and therapeutic hypotheses that are early-stage but potentially transformative,\u201d said James Flynn, Managing Partner of Deerfield. \u201cMoving these hypotheses from the lab toward the clinic requires significant financial resources to build on work launched by philanthropy and grants, and are not yet far enough along to attract traditional venture funding or pharmaceutical collaborations. We are prepared to fund and develop these projects so Broad researchers can immediately pursue bold ideas, and have confidence that real breakthroughs will have additional support to move toward clinical success.\u201d \nThis partnership follows the Broad Institute\u2019s principles for disseminating scientific innovations , which aim to ensure that others can build on scientific advances made by the Broad community to maximize the benefit for human health. Knowledge and intellectual property developed will be shared widely with other academic and non-profit research institutions, and may also be made available for commercial therapeutic development. \n\u201cOver the last decade, scientific advances have made it possible to rapidly understand the biological basis of disease at unprecedented resolution,\u201d said Eric S. Lander, president and founding director of the Broad Institute. \u201cThe challenge now is to develop ways to speed the process of turning these scientific insights into therapies that benefit patients.\u201d \n\u201cWe are thrilled to work with Deerfield Management, which is aligned with our institutional mission and values,\u201d said Issi Rozen, chief business officer at the Broad Institute. \u201cThis collaboration will allow our researchers to proceed with high-impact work that will benefit the patient in the long-term.\u201d \nAbout Deerfield \nDeerfield is an investment management firm committed to advancing healthcare through investment, information and philanthropy. For more information, please visit www.deerfield.com . \nAbout the   Harvard \n  Harvard was launched in 2004 to empower this generation of creative scientists to transform medicine. The Broad Institute seeks to describe all the molecular components of life and their connections; discover the molecular basis of major human diseases; develop effective new approaches to diagnostics and therapeutics; and disseminate discoveries, tools, methods, and data openly to the entire scientific community. \nFounded by MIT, Harvard, Harvard-affiliated hospitals, and the visionary Los Angeles philanthropists Eli and Edythe L. Broad, the Broad Institute includes faculty, professional staff, and students from throughout the MIT and Harvard biomedical research communities and beyond, with collaborations spanning over a hundred private and public institutions in more than 40 countries worldwide. For further information about the Broad Institute, go to http://www.broadinstitute.org . \nFor more information, contact:", "highlightText": "", "highlightTitle": "", "language": "english", "external_links": [], "entities": {"persons": [{"name": "eric s. lander", "sentiment": "none"}, {"name": "issi rozen", "sentiment": "none"}, {"name": "eli", "sentiment": "none"}, {"name": "edythe l. broad", "sentiment": "none"}, {"name": "james flynn", "sentiment": "none"}], "organizations": [{"name": "broad institute", "sentiment": "negative"}, {"name": "broad institute and deerfield management", "sentiment": "negative"}, {"name": "deerfield management", "sentiment": "negative"}, {"name": "harvard", "sentiment": "none"}, {"name": "kelly davidson by broad communications new", "sentiment": "none"}, {"name": "deerfield foundation", "sentiment": "none"}, {"name": "mit", "sentiment": "none"}, {"name": "harvard    harvard", "sentiment": "none"}], "locations": [{"name": "deerfield  deerfield", "sentiment": "none"}, {"name": "los angeles", "sentiment": "none"}, {"name": "deerfield", "sentiment": "none"}]}, "rating": null, "crawled": "2017-10-10T16:07:42.000+03:00"}, {"thread": {"uuid": "ff4980b73ddd1396dab04912de41a38e4184c2d3", "url": "http://omgili.com/ri/.wHSUbtEfZShuqU8OSon1xB4C1imBQp0GiyuUFwR9Loa_5aMlHsGWmxzYxmEwehFEmhuHU9icRd7LxMyyI1psw--", "site_full": "www.broadinstitute.org", "site": "broadinstitute.org", "site_section": "https://www.broadinstitute.org/rss.xml", "site_categories": ["health"], "section_title": "Broad Institute", "title": "CellProfiler goes 3D", "title_full": "CellProfiler goes 3D", "published": "2017-10-16T19:00:00.000+03:00", "replies_count": 0, "participants_count": 1, "site_type": "blogs", "country": "US", "spam_score": 0.0, "main_image": "", "performance_score": 0, "domain_rank": 45479, "social": {"facebook": {"likes": 0, "comments": 0, "shares": 0}, "gplus": {"shares": 0}, "pinterest": {"shares": 0}, "linkedin": {"shares": 0}, "stumbledupon": {"shares": 0}, "vk": {"shares": 0}}}, "uuid": "ff4980b73ddd1396dab04912de41a38e4184c2d3", "url": "http://omgili.com/ri/.wHSUbtEfZShuqU8OSon1xB4C1imBQp0GiyuUFwR9Loa_5aMlHsGWmxzYxmEwehFEmhuHU9icRd7LxMyyI1psw--", "ord_in_thread": 0, "author": "tulrich@broadinstitute.org", "published": "2017-10-16T19:00:00.000+03:00", "title": "CellProfiler goes 3D", "text": "Credit : Kyle Karhohs, Broad Imaging Platform By Tom Ulrich A new release of CellProfiler \u2014 the free, open-source quantitative image analysis package developed in the Broad Imaging Platform \u2014 brings a host of new capabilities, including 3D image analysis. \nBroad institute scientist and Imaging Platform director Anne Carpenter and her team released CellProfiler 3.0 , a new version of their flagship free, open-source software package for quantitative analysis of biological images. \nCarpenter laid out CP3.0\u2019s new features and capabilities \u2014 including 3D image processing and deep learning capabilities \u2014 in a post for the imaging community on the CellProfiler blog . As she explained: \nEighteen months in the making, this is the first version of CellProfiler that can identify objects in 3D images volumetrically \u2013 the result of a collaboration with the Allen Institute for Cell Science who funded the project together with NIH. If you\u2019ve not yet seen it, the Allen Cell Explorer is a real visual and biological treat! So many researchers require completely automated analysis of 3D images, as more complex cell organoids are entering mainstream research. The new capabilities of CellProfiler aim to address this growing need. \nAlthough there are no massive changes in the remainder of CellProfiler\u2019s interface, a LOT has improved under the hood since the last release. The thousands of researchers using CellProfiler will probably notice the change in speed though: not just startup speed but also roughly 2-fold improvement in the time it takes to process a typical pipeline. It adds up particularly if you are paying for cloud computing resources! Speaking of which, we recently created Distributed-CellProfiler , which allows running jobs on Amazon Web Services, even if you\u2019re not a computational expert. \nWe\u2019ve made substantial progress simplifying CellProfiler\u2019s installation. In addition to the macOS and Windows releases of CellProfiler we\u2019ve started packaging a CellProfiler release for Linux that will ease installation across Linux distributions. We\u2019ve also started packaging CellProfiler for a variety of formats, for example, a Python wheel is now available from the Python Package Index and a Docker image is now available from Docker Hub. In an effort to see new uses for CellProfiler we\u2019ve made CellProfiler much simpler to compile on a variety of familiar and unusual platforms by requiring fewer dependencies and only using ubiquitous build systems. \nThose taking a peek at the code will notice 3.0 is massively trimmed down, in part due to better integration with Python\u2019s scientific community. We\u2019ve contributed most of CellProfiler\u2019s fundamental image analysis, image processing, and image segmentation algorithms to scikit-image making them readily available as a package to those writing their own imaging applications. \nAnd for the machine learning enthusiasts out there, CellProfiler is the first biologist-friendly software we are aware of that can integrate deep learning! You might have noticed convolutional neural networks in the news, as they\u2019ve been massively successful lately, especially for computer vision tasks. There are now preliminary demonstrations of using a TensorFlow and a Caffe model with CellProfiler. \nAdditional details about the release are available on the CellProfiler blog . And CellProfiler 3.0 is available for download now at cellprofiler.org/releases/ . \nUsing the new 3D functionality within CellProfiler 3.0, a monolayer of HeLa cells is segmented, with the nuclei and cytoplasm of each cell uniquely labeled. CellProfiler measures 3D aspects of each object (e.g., volume, surface area), providing the data required to quantify 3D spatial relationships between cellular components. (Credit: Kyle Karhohs)", "highlightText": "", "highlightTitle": "", "language": "english", "external_links": [], "entities": {"persons": [{"name": "kyle karhohs", "sentiment": "negative"}, {"name": "tom ulrich", "sentiment": "negative"}, {"name": "anne carpenter", "sentiment": "none"}, {"name": "carpenter", "sentiment": "none"}, {"name": "python", "sentiment": "none"}], "organizations": [{"name": "amazon web services", "sentiment": "none"}, {"name": "docker hub", "sentiment": "none"}, {"name": "allen institute for cell science", "sentiment": "none"}, {"name": "nih", "sentiment": "none"}], "locations": []}, "rating": null, "crawled": "2017-10-16T20:22:35.000+03:00"}, {"thread": {"uuid": "120b6b788a80c0db781866f9b1f456a3094cced1", "url": "http://omgili.com/ri/.wHSUbtEfZShuqU8OSon1xB4C1imBQp0AXD41xSVYVkEud0NSYz45KN2nPmxPpJAi5YD5LyiVqlO1yKr2Ype44u18AW3MyusqQgO2KcbGI5RoQb5RBrfWpyFmYiUt9DV", "site_full": "www.broadinstitute.org", "site": "broadinstitute.org", "site_section": "https://www.broadinstitute.org/rss.xml", "site_categories": ["health"], "section_title": "Broad Institute", "title": "Models, Inference & Algorithms", "title_full": "Models, Inference & Algorithms", "published": "2017-10-11T08:00:00.000+03:00", "replies_count": 0, "participants_count": 1, "site_type": "news", "country": "US", "spam_score": 0.0, "main_image": "", "performance_score": 0, "domain_rank": 45479, "social": {"facebook": {"likes": 0, "comments": 0, "shares": 0}, "gplus": {"shares": 0}, "pinterest": {"shares": 0}, "linkedin": {"shares": 0}, "stumbledupon": {"shares": 0}, "vk": {"shares": 0}}}, "uuid": "120b6b788a80c0db781866f9b1f456a3094cced1", "url": "http://omgili.com/ri/.wHSUbtEfZShuqU8OSon1xB4C1imBQp0AXD41xSVYVkEud0NSYz45KN2nPmxPpJAi5YD5LyiVqlO1yKr2Ype44u18AW3MyusqQgO2KcbGI5RoQb5RBrfWpyFmYiUt9DV", "ord_in_thread": 0, "author": "admin", "published": "2017-10-11T08:00:00.000+03:00", "title": "Models, Inference & Algorithms", "text": "Home Models, Inference & Algorithms \nModels, Inference & Algorithms (MIA) is a Broad initiative to support learning and collaboration across the interface of biology and mathematics / statistics / machine learning / computer science. \nOur core activity is the Wednesday morning meeting in the Monadnock room (415 Main St, 2nd floor), featuring a method primer at 9, a main seminar with breakfast at 10, and a discussion with the speaker at 11. These meetings grew out of the Stat Math Reading Club (SMRC), a series of informal and pedagogical board talks; over a year and a half the talks attracted an ever-larger audience from Broad and the wider Boston community. With MIA we strive to maintain SMRC's essential character, emphasizing lucid exposition of broadly applicable ideas over rapid-fire communication of research results and encouraging questions from the audience throughout. In addition to the weekly meeting there are a number of other MIA activities. Please contact to be added to our mailing list and learn more. \nThe MIA Initiative is led by Jon Bloom and Alex Bloemendal, and affiliated with the Data Sciences Platform, the Office of the Chair of the Faculty, and the MIT math department. The MIA community has been enriched by the awesome efforts of Hilary Finucane, David Benjamin, Yakir Reshef, Umut Eser, David Rolnick, Ryan Peckner, Ann Sizemore, and many others. SMRC thrived in collaboration with Bertrand Haas, Anthony Phillipakis, Yossi Farjoun, and Cotton Seed. \nMIA Playlist: Check out and share our growing library of MIA Primer Seminar videos , algorithmically-paired for your pedagogical pleasure. \nTalking Machines: Check out interviews with Director Eric Lander , Faculty Chair Aviv Regev , and MC* Nick Patterson on our favorite ML podcast! *Master of Computation \nFall 2017 Schedule: 9:00am Primer, 9:50am Breakfast, 10:00am Seminar, 11:00am Discussion; all in Monadnock Date Hilary Finucane [ video ] Broad Fellow NO MEETING due to ASHG 2017 \nCalico Labs \nReading the rules of gene regulation from the human noncoding genome \nAbstract: Functional genomics approaches to better model genotype-phenotype relationships have important applications toward understanding genomic function and improving human health. In particular, thousands of noncoding loci associated with diseases and physical traits lack mechanistic explanation. I'll present a machine-learning system to predict cell type-specific epigenetic and transcriptional profiles in large mammalian genomes from DNA sequence alone. Using convolutional neural networks, this system identifies promoters and distal regulatory elements and synthesizes their content to make effective gene expression predictions. I'll show that model predictions for the influence of genomic variants on gene expression align well to causal variants underlying eQTLs in human populations and can be useful for generating mechanistic hypotheses to enable GWAS loci fine mapping. \nSamuel Friedman Broad Data Sciences Platform \nPrimer: Classifying genomic sequences with convolutional neural networks \nAbstract: Initially developed for image processing, Convolutional Neural Networks (CNNs) have been applied to genomic data with promising results. This primer will trace some of the history of neural networks with an eye towards the practical lessons learnt along the way. Then building on the idea of the Position Weight Matrix as a motif detector we will explore exactly what convolution means when applied to a DNA sequence. While drawing examples from computer vision and natural language processing, our focus will be on the application of CNNs to genomic data. Lastly, we will cover recent advances in CNNs including residual connections and dilated convolutions. \nSeptember 13, 2017 \nHarvard CS, Harvard/MIT MD/PhD program \nDetecting effects of transcription factors on disease \nAbstract: Learning biology using GWAS data frequently involves identifying genomic regions involved in a biological process and assessing for enrichment of GWAS signal in those regions. But in some cases, e.g., binding of a transcription factor (TF), improving models and growing data sets allow us to estimate in a signed way whether genetic variants promote or hinder a biological process. I'll present a new method, signed LD profile regression, for combining this type of information with GWAS data to draw relatively strong inferences about trait mechanism. I'll then describe how this method can be applied in conjunction with signed genomic annotations reflecting binding of ~100 TFs in various cell lines generated using a convolutional neural network, Basset. Finally, I'll discuss some results from applying our method to GWAS data about a range of traits including gene expression, epigenetic traits, and several diseases. \nFinucane Lab, Broad Institute \nPrimer: Generalized least squares \nAbstract: Linear models are a very common choice when modeling the relation between inputs and outputs because of their simplicity and interpretability. We will explore methods for parameter estimation in these models, with an eye toward understanding some of the more advanced techniques. We will start by reviewing the most commonly used estimator: the ordinary least squares (OLS) estimator. Then we will explore some limitations of the OLS estimator when the residuals are not i.i.d. and discuss how to overcome these limitations, first with with weighted least squares and then with generalized least squares. We'll close by discussing linear models in the context of genome-wide association studies (GWAS) as a lead-in to the talk. \nSeptember 20, 2017 \nBroad / HMS \nLearning phylogeny through f-statistics \nAbstract: f-statistics are now a commonplace tool in population genetics, used to discover and test models for demographic history. We describe the theory and ADMIXTOOLS, a package that implements most of the tests used. We give a number of examples of discoveries about human history made using f-statistics and conclude with some things we would like to do better and some open questions. [ paper ] \nSeptember 27, 2017 \nBroad Institute, MIT Statistics \nLearning developmental landscapes from single-cell gene expression with optimal transport \nAbstract: Understanding the molecular programs that guide cellular differentiation during development is a major goal of modern biology. Here, we introduce an approach, WADDINGTON-OT, based on the mathematics of optimal transport, for inferring developmental landscapes, probabilistic cellular fates and dynamic trajectories from large-scale single-cell RNA-seq (scRNA-seq) data collected along a time course. We demonstrate the power of WADDINGTON-OT by applying the approach to study 65,781 scRNA-seq profiles collected at 10 time points over 16 days during reprogramming of fibroblasts to iPSCs. We construct a high-resolution map of reprogramming that rediscovers known features; uncovers new alternative cell fates including neural- and placental-like cells; predicts the origin and fate of any cell class; highlights senescent-like cells that may support reprogramming through paracrine signaling; and implicates regulatory models in particular trajectories. Of these findings, we highlight Obox6, which we experimentally show enhances reprogramming efficiency. Our approach provides a general framework for investigating cellular differentiation. [ paper ] \nENS Paris Mathematics \nPrimer: A tutorial on optimal transport \nAbstract: The optimal transport (OT) problem is often described as that of finding the most efficient way of moving a pile of dirt from one configuration to another. Once stated formally, OT provides extremely useful tools for comparing, interpolating and processing objects such as distributions of mass, probability measures, histograms or densities. This talk is an up-to-date tutorial on a selection of topics in OT. In the first part, I will give an intuitive description of OT, its behavior and basic properties. I will also explain a useful extension of the theory to deal with unnormalized distributions of mass. In the second part, I will introduce state-of-the-art numerical methods for solving OT related problems, namely scaling algorithms based on entropic regularization. \nOctober 4, 2017 \nBroad Fellow \nInsight into the biology of common diseases using summary statistics of large genome-wide association studies \nAbstract: Data from genome-wide association studies (GWAS) contain valuable information about the genetic basis of the disease. For most common diseases, obtaining insights from these data is difficult because the signal is very diffuse: there are likely thousands or tens of thousands of causal variants, each with a very small effect size on disease risk. Moreover, for many of the largest disease GWAS, no individual researcher has access to all of the genotype data; rather, the only data available are meta-analyzed marginal effect size estimates for each variant. I will describe a powerful approach to modeling these summary statistics that allows us, for example, to identify disease-relevant tissues and cell types, or to quantify the degree to which two traits have a common genetic basis. The approach, called LD score regression, is based on a commonly used model in genetics in which the effect size of each variant on the disease is random. The parameters of this model provide information about the disease such as whether regions of the genome active in a given tissue (e.g., liver) tend to be more associated with disease than regions of the genome active in a second tissue (e.g., brain). I will present results from an application of LD score regression to identify relevant tissues and cell types from several large GWAS, and from an application of LD score regression to identify pairs of phenotypes with shared genetic basis. [papers 1 , 2 , 3 , 4 ] \nOctober 11, 2017 \nHacohen Lab, Broad / MGH; Neon Thereapeutics \nImproving the rules of endogenous antigen prediction to support personalized cancer vaccine development \nAbstract: In the seminar, we will see how tumor-specific mutations (neo-antigens) can stimulate the immune recognition of cancer cells and be used as a therapeutic strategy. For such strategy to be successful, we need to be able to predict which endogenous peptide antigens will be presented on the cell surface by polymorphic HLA class I gene variants. We will present analyses of our single HLA peptide data which allowed us to develop improved rules for endogenous peptide presentation based on the physicochemical properties of binding peptides, patterns of peptide cleavage and abundance of cognate transcripts. Incorporating these findings into neural network models improved prediction of endogenous peptide binding as compared to current predictive algorithms. We will end by reviewing very encouraging results from a tumor vaccine trial in melanoma patients. \nMichael Rooney Neon Therapuetics \nPrimer: Tumor immunity \nAbstract: In the primer, we will introduce the basics of how the adaptive immune system recognizes diseased cells and see that immune responses rely on the ability of cytotoxic T cells to identify and eliminate cells that display disease-associated antigens bound to specific cell-surface receptors (the human leukocyte antigen (HLA) class I molecules). We will discuss how this mechanism extends to cancer, what are some strategies by which tumors evade immune detection, and what are the therapeutic interventions that can boost immune clearance of tumors. \nOctober 25, 2017 \nMIT CSAIL, HMS, Harvard CS \nDetecting novel associations in large data sets \nAbstract: As data sets grow in dimensionality, making sense of the wealth of interactions they contain has become a daunting task, not just due to the sheer number of relationships but also because relationships come in different forms (e.g. linear, exponential, periodic, etc.) and strengths. If you do not already know what kinds of relationships might be interesting, how do you find the most important or unanticipated ones effectively and efficiently? This is commonly done by using a statistic to rank relationships in a data set and then manually examining the top of the resulting list. For such a strategy to succeed though, the statistic must give similar scores to equally noisy relationships of different types. In this talk we will formalize this property, called equitability, and show how it is related to a variety of traditional statistical concepts. We will then introduce the maximal information coefficient, a statistic that has state-of-the-art equitability in a wide range of settings, and discuss how its equitability translates to practical benefits in the search for dependence structure in high-dimensional data using examples from global health and the human gut microbiome. \nMIT CSAIL, HMS, Harvard CS \nPrimer: Hypothesis testing and measures of dependence \nAbstract: Searching for departures from statistical independence in data is a fundamental problem that has been formalized in a variety of ways. We will cover two frameworks in which this problem has historically been understood. The first is statistical and involves framing the search as a hypothesis test in a finite-sample setting. The second is probabilistic and involves defining functions of random variables that have useful properties in the large-sample limit. We will close with a discussion of common themes underlying measures of dependence arising from each of these paradigms. \nNovember 1, 2017 \nMIT Math \nMessage passing algorithms for cryo-EM and synchronization \nAbstract: Cryo-electron microscopy is a promising imaging technique in structural biology, yielding a large number of very noisy images of a macromolecule in different, unknown rotations. The computational task of reconciling these images into a 3D model of the molecule has proven both mathematically rich and challenging, leading to a mathematical formulation of \"synchronization\" problems: the learning task of aligning rotated objects based on noisy measurements of their pairwise relative rotations. We present an algorithm following the framework of approximate message passing, which statistical physics suggests may yield the optimal efficient reconstruction. Our approach leverages the representation theory of compact groups to give a unified, general theory for problems with various conceptual 'rotations' or 'alignments'. (Joint work with Amelia Perry, Afonso Bandeira, and Ankur Moitra.) \nSpring 2017 Schedule: 8:30am Primer, 9:20am Breakfast, 9:30am Seminar, 10:30am Discussion; all in Monadnock Date Lineup includes Matei Zaharia, Ion Stoica, and our own Cotton Seed Feb 15 Carl de Boer [ video , slides ] Regev Lab Kharchenko Lab, Harvard Medical School Linking genetic and transcriptional intratumoral heterogeneity at the single cell level \nDepartment of Systems Biology, Harvard Medical School \nStructure and fitness from genomic sequences \nAbstract: The evolutionary trajectories of biological sequences are propelled by mutation and whittled away by selection to maintain and develop function. Present day sequences can therefore be regarded as the outcomes of millions of evolutionary experiments that record functional constraints in the genotype-phenotype map. In this talk I will first recap the primer by John and Adam that describes how a generative model for sequences can quantify evolutionary constraints on biomolecules in terms of couplings between specific residue combinations. I will show how we have applied this model to predict (i) accurate 3D structures of proteins, RNA and complexes, (ii) conformational plasticity of \u2018disordered\u2019 proteins, (iii) quantitative effects of mutations on organism fitness, and (iv) designed sequences of proteins with desired properties. These computational approaches address the challenge of inferring causality from correlations in genetic sequences but can be applied more widely to other biological information such as gene expression or dynamics, cellular phenotypes or drug response. I will introduce challenges and opportunities for extending these methods to diverse biomedical and engineering applications. \nMarks Lab, Department of Systems Biology, Harvard Medical School \nPrimer: Generative models of biological sequence families \nAbstract: Modern genome sequencing and synthesis can acquire and generate tremendous molecular diversity in a day, but our ability to navigate and interpret the exponentially large space of potential biological sequences remains limited. Central to this challenge is the lack of a priori knowledge about epistasis, i.e. non-additive interactions between positions in a molecule or genome. We will describe a class of generative models, discrete undirected graphical models, that, when fit to deep evolutionary sequence variation, can reveal both the three dimensional structures and mutational landscapes of proteins and RNAs, described in more detail in the talk by Debora after the break. In this primer, we will review the math and intuition behind these models, how they require approximate methods for scalable inference, and connections to other common methods in quantitative biology such as partial correlations and logistic regression. Lastly, we will outline how to go beyond pairwise and detect higher order epistasis with neural-network-powered generative models. \nFebruary 22, 2017 \nU Penn School of Medicine \nGone Fishing: Unsupervised methods for discovery from public data \nAbstract: Public gene expression data are abundant. Anybody with an internet connection can download more than 2 million genome-wide assays of gene expression. Learning from these data remains challenging. For example, public data often lack the annotations that enable traditional meta-analysis. If we could surmount these barriers, however, we'd have a valuable resource at our fingertips. Our lab uses machine learning methods to integrate these heterogeneous, noisy, and often poorly or incorrectly annotated data. We focus specifically on algorithms that are unsupervised and robust to noise in order to tackle unannotated data. We've shown that these algorithms can robustly reveal biological features in data from cancer biopsies to microbial systems. And we share these algorithms by building user-friendly software and web servers. Our aim is to make the reproducible analysis of big public data as routine in life sciences labs as wet-bench techniques like PCR. \nGreene Lab \nPrimer: Integrating biomedical knowledge to predict new uses for existing drugs \nAbstract: How do you teach a computer biology? Our goal was to predict new uses for existing drugs. But we're data scientists, not pharmacologists. So we set out to encode the knowledge from millions of biomedical studies from the last half century. Using a heterogeneous network (hetnet) as our data structure, we were able to condense a large portion of biomedical knowledge into a network with 47,031 nodes of 11 types and 2,250,197 relationships of 24 types. The network is named Hetionet v1.0 and lives at https://neo4j.het.io . Hetionet enables queries that span many types of information. While such queries were possible before Hetionet, they often took months of data integration, preprocessing, and specialized query scripts. Now complex queries can be written in minutes using the Cypher query language for hetnets. Accordingly, we were able to perform ~47 million queries to assess the connectivity between 136 diseases and 1,538 compounds. Next, we compiled a catalog of 755 disease-modifying treatments and learned which types of network paths could predict whether a compound treats a disease. In total, we predicted probabilities of treatment for 209,168 compound-disease pairs ( http://het.io/repurpose ). Our method also allows you to compare which types of information were valuable for predicting drug efficacy. Project Rephetio, the codename for this project, was performed openly online in realtime ( https://doi.org/bszr ). In total, 40 community members provided feedback across 86 project discussions. Attend the primer to learn more about Project Rephetio & Hetionet as well as hetnets for data integration and the Neo4j graph database. Research continuous as a set of open source GitHub repositories, allowing anyone interested to get involved. div class=\"talk\">\nHarvard Chemistry and Chemical Biology \nDeep learning chemical space\u200b\u200b:\u200b a variational autoencoder for automatic molecular design \nAbstract: Virtual screening is increasingly proven as a tool to test new molecules for a given application. Through simulation\u200b and regression\u200b we can gauge whether a molecule will be a promising candidate in an automatic and robust way. A large remaining challenge, however, is how to perform optimizations over a discrete space of size at least 10^60. Despite the size of chemical space, or perhaps precisely because of it, coming up with novel, stable, makeable molecules that are effective is not trivial. First-principles approaches to generating new molecules fail to capture the intuition embedded in the ~100 million existing molecules. I will report our progress towards developing an autoencoder that allows us to project molecular space into a continuous, differentiable representation where we can perform molecular optimization. \nMarch 8, 2017 \nRegev Lab, Broad Institute \nLearning the rules of gene regulation with millions of synthetic promoters \nAbstract: Gene regulatory programs are encoded in the sequence of the DNA. However, how the cell uses transcription factors (TFs) to interpret regulatory sequence remains incompletely known. Synthetic regulatory sequences can provide insight into this logic by providing additional examples of sequences and their regulatory output in a controlled setting. Here, we have measured the gene expression output of tens of millions of unique promoter sequences, whose expressions span a range of 1000-fold, in a controlled reporter construct. This vast dataset of expression-DNA pairs represents a unique machine learning opportunity, and we use it to build quantitative models of transcriptional regulation based on biochemical principles. Even with a naive \u201cbillboard\u201d model of gene regulation (with no positioning or complex TF-interactions), we can explain upwards of 92% of the variation in expression. We gain numerous insights into gene regulation, including a quantitative description of activation, repression, and chromatin modification for each TF, consistent with known TF activities and condition-specific regulators, and even use our data to refine the specificities of TFs. Although a \u201cbillboard\u201d model explains the majority of expression in our system, certain TFs show position-, orientation-, and even DNA helical-face-dependent activities. We have so many promoter examples that we can look for potential spacing/orientation-dependent interactions between most TF pairs at base pair resolution, and find certain interactions consistent with biochemical cooperativity. Altogether, the principles learned here help us to better understand when and where TFs bind DNA, what they do when they get there, and how regulatory sequences evolve. \nMarch 15, 2017 \nData Sciences & Data Engineering, Broad \nA scalable Bayesian framework for inferring copy number variation \nAbstract: Inferring copy number variation (CNV) from next-generation sequencing (NGS) data is a challenging problem. On the one hand, the complexity of the NGS technology results in a highly non-uniform sampling of the genome with unknown latent factors. On the other hand, devising and implementing modern machine learning algorithms for CNV inference in a scalable and robust fashion is an arduous task due to the sheer size of the data. In this talk, we briefly review the existing approaches and glance over a number of their caveats, including difficulty with sex chromosomes, lack of a data-driven model for determining the number of bias latent factors, neglect of sampling noise, heuristic filtering and outlier detection, lack of self-consistency and scalability. Next, we introduce GATK gCNV, our principled and scalable Bayesian framework for germline CNV inference from whole-exome sequencing (WES) and whole-genome sequencing (WGS) data that addresses these caveats. We benchmark GATK gCNV, XHMM and CODEX on WES data against high-confidence Genome STRiP calls on matched WGS data as ground truth, and show that GATK gCNV yields up to 30 percent higher sensitivity and specificity compared to the existing tools. We conclude the talk with a brief discussion of our ongoing efforts toward addressing the difficulty with common and large CNV events, and generalization to somatic CNV inference. \nSamuel Lee Data Sciences & Data Engineering, Broad \nPrimer: Bayesian PCA \nAbstract: The model at the heart of GATK gCNV builds heavily on the probabilistic and Bayesian approaches to principal component analysis (PCA). In contrast with traditional PCA, the probabilistic approach provides a predictive model that can account for missing data, while the fully Bayesian approach further enables a principled way to learn the effective dimensionality of the principal subspace (i.e., the appropriate number of principal components to use). Model inference can be performed using expectation-maximization and variational-Bayesian methods, respectively. We will give a pedagogical overview of these methods, drawing analogies between Bayesian PCA and the perhaps more familiar Gaussian mixture model. \nMarch 22, 2017 \nMIT IDSS, CSAIL, EECS \nProbabilistic models of diversity: applications and algorithms for determinantal point processes \nAbstract: Determinantal Point Processes (DPPs) are gaining popularity in machine learning as elegant probabilistic models of diversity. In other words, these are probability distributions over subsets of a collection of items (data points, features, ...) that prefer diverse subsets. In particular, many computations that are difficult with other models \"simply\" reduce to linear algebra for DPPs. DPPs have been known to arise in statistical physics, combinatorial probability and random matrix theory, and certain approximation algorithms. The first part of this talk will survey machine learning-related applications of DPPs, from recommendation, feature selection and improving interpretability to matrix approximations for kernel methods and pruning of neural networks. Despite their ease of modeling, the wide applicability of DPPs has been hindered by computationally expensive sampling algorithms. The second part of the talk will address recent progress in sampling algorithms for DPPs and its implications in theory and practice. Most of the talk will be tutorial-style and does not require any prior knowledge of DPPs. Based on joint work with Chengtao Li and Suvrit Sra. \nMIT IDSS, CSAIL, EECS \nPrimer: A primer on determinantal point processes \nAbstract: The primer will be a short tutorial that introduces Determinantal Point Processes with a bit of detail and intuition, explains its relations to diversity, basic computations, and important models. div class=\"talk\">\nMIT Earth And Planetary Sciences, Greka Lab \nA pseudo-random walk from new worlds to diabetes \nAbstract: For centuries, our understanding of planetary systems has been based on observations of a unique sample, the Solar System. Similarly, our perspective on Life and habitats has remained Earth-centric, leaving millennia-old questions such as \"Are we alone? Where/How/When did Life emerge?\" unanswered. Two decades ago, the first planet orbiting another star than ours\u2014a.k.a. an exoplanet\u2014was discovered, opening a new chapter of space exploration. Since then, over 3,500 exoplanets have been found in over 2,500 other systems; a sample size increase of three orders of magnitude that has already yielded profound changes in our understanding of planetary systems. Similar changes await our perspective on Life and habitats within the next generation. During this talk, a \u201cSearching for New Worlds 101\u201d will be provided to introduce the TRAPPIST \u2013 1 system, exploring our recent discovery of Earth-sized planets that are both potentially habitable and amenable for in-depth studies with upcoming observatories, and the first insights into their atmospheres, as revealed by the Hubble Space Telescope. At the other end of the scale, biology focuses on chemical processes within cells rather than within atmospheres. A fundamental\u2014and yet mostly overlooked\u2014set of cellular processes gravitates around transient calcium signals. The availability of fast fluorescent calcium indicators allows for the measurements of intracellular calcium and thus provides direct observables of pathological and physiological calcium fluctuations. Calcium signals thereby offer new perspectives to approach a variety of diseases, from diabetes and metabolic disease to Alzheimer's disease. Interestingly, these seemingly diverse fields of biology and planetary sciences share a common cornerstone: (Spectro)Photometric time series. With the arrival of high throughput facilities (e.g. TESS for exoplanetary sciences; FLIPR for biology), the need for standardized data acquisition/processing tools has emerged. The inherent similarity between these fields, in terms of multidisciplinarity and datatype, allows for mutually-beneficial collaborations that need to be leveraged to support the optimal sampling of yet unexplored parameter spaces, and their unbiased interpretation. \nApril 5, 2017 \nLander Lab, Broad Institute \nGrand Challenge: Mapping the regulatory wiring of the genome \nAbstract: Our cells are controlled by complex molecular instructions encoded in the \"noncoding\" sequences of our genome, and alterations to these noncoding sequences underlie many common human diseases. The grammar of these noncoding sequences has been difficult to study, but the recent confluence of methods for both high-throughput measurement and high-throughput perturbation offers new opportunities to understand these sequences at a systems level. In this talk, I will highlight outstanding challenges in gene regulation where applying computational approaches in combination with emerging genomics datasets may allow us to build integrated maps that describe the regulatory wiring of the genome. As an example, I will present our efforts to experimentally and computationally map the functional connections between promoters and distal enhancers and use this information to understand human genetic variation in the noncoding genome. \nApril 12, 2017 \nGoogle Brain \nComposing graphical models with neural networks for structured representations and fast inference \nAbstract: I'll describe a new modeling and inference framework that combines the flexibility of deep learning with the structured representations of probabilistic graphical models. The model family augments latent graphical model structure, like switching linear dynamical systems, with neural network observation likelihoods. To enable fast inference, we show how to leverage graph-structured approximating distributions and, building on variational autoencoders, fit recognition networks that learn to approximate difficult graph potentials with conjugate ones. I'll show how these methods can be applied to learn how to parse mouse behavior from depth video. \nColumbia, Blei Lab \nPrimer: Bayesian time series modeling with recurrent switching linear dynamical systems \nAbstract: Many natural systems like neurons firing in the brain or basketball teams traversing a court give rise to time series data with complex, nonlinear dynamics. We gain insight into these systems by decomposing the data into segments that are each explained by simpler dynamical units. Bayesian time series models provide a flexible framework for accomplishing this task. This primer will start with the basics, introducing linear dynamical systems and their switching variants. With this background in place, I will introduce a new model class called recurrent switching linear dynamical systems (rSLDS), which discover distinct dynamical units as well as the input- and state-dependent manner in which units transition from one to another. In practice, this leads to models that generate much more realistic data than standard SLDS. Our key innovation is to design these recurrent SLDS models to enable recent P\u00f3lya-gamma auxiliary variable techniques and thus make approximate Bayesian learning and inference in these models easy, fast, and scalable. \nApril 19, 2017 \nWellcome Trust Centre for Human Genetics, Oxford \nSimulating, storing and processing genetic variation data for millions of samples \nAbstract: Coalescent theory has played a key role in modern population genetics and is fundamental to our understanding of genetic variation. While simulation has been essential to coalescent theory from its beginnings, simulating realistic population-scale genome-wide data sets under the exact model was, until recently, considered infeasible. Even under an approximate model, simulating more than a few tens of thousands samples was very time consuming and could take several weeks to complete a single replicate. However, by encoding simulated genealogies using a new data structure (called a tree sequence), we can we now simulate entire chromosomes for millions of samples under the exact coalescent model in a few hours. We discuss some applications that these simulations have made possible, including a study of biases in human GWAS and the systematic benchmarking of variant processing tools at scale. The tree sequence data structure is also an extremely concise way of representing genetic variation data, and we show how variant data for millions of simulated human samples can be stored in only a few gigabytes. Moreover, we show that this very high level of compression does not incur a decompression cost. Because the information is represented in terms of the underlying genealogies, operations such as computing allele frequencies on sample subsets or measuring of linkage disequilibrium can be made very efficient. Finally, we discuss ongoing work on inferring tree sequences from observed data and present some preliminary results. \nApril 26, 2017 \nDepartment of Biomedical Informatics, Harvard Medical School \nFrom one to millions of cells: computational challenges in single-cell analysis \nAbstract: Over the last five years, our ability to isolate and analyze detailed molecular features of individual cells has expanded greatly. In particular, the number of cells measured by single-cell RNA-seq (scRNA-seq) experiments has gone from dozens to over a million cells, thanks to improved protocols and fluidic handling. Analysis of such data can provide detailed information on the composition of heterogeneous biological samples, and variety of cellular processes that altogether comprise the cellular state. Such inferences, however, require careful statistical treatment, to take into account measurement noise as well as inherent biological stochasticity. I will discuss several approaches we have developed to address such problems, including error modeling techniques, statistical interrogation of heterogeneity using gene sets, and visualization of complex heterogeneity patterns, implemented in PAGODA package. I will discuss how these approaches have been modified to enable fast analysis of very large datasets in PAGODA2, and how the flow of typical scRNA-seq analysis can be adapted to take advantage of potentially extensive repositories of scRNA-seq measurements. Finally, I will illustrate how such approaches can be used to study transcriptional and epigenetic heterogeneity in human brains. \nHarvard Medical School, Kharchenko Lab \nPrimer: Linking genetic and transcriptional intratumoral heterogeneity at the single cell level \nMay 10, 2017 \nBroad Fellow, Chemical Biology & Therapeutic Sciences \nContinuous directed evolution: advances, applications, and opportunities \nAbstract: The development and application of methods for the laboratory evolution of biomolecules has rapidly progressed over the last few decades. Advancements in continuous microbe culturing and selection design have facilitated the development of new technologies that enable the continuous directed evolution of proteins and nucleic acids. These technologies have the potential to support the extremely rapid evolution of biomolecules with tailor-made functional properties. Continuous evolution methods must support all of the key steps of laboratory evolution \u2014 translation of genes into gene products, selection or screening, replication of genes encoding the most fit gene products, and mutation of surviving genes \u2014 in a self-sustaining manner that requires little or no researcher intervention. In this presentation, I will describe the basis and applications of our Phage-Assisted Continuous Evolution (PACE) platform, solutions we have devised to address known limitations in the technique, and opportunities to improve PACE where in silico computation may play a key role. Through these tools, we aspire to enable researchers to address increasingly complex biological questions and to access biomolecules with novel or even unprecedented properties. \nMay 17, 2017 \nMIT EECS, CSAIL, and IDSS \nEdge-exchangeable graphs, clustering, and sparsity \nAbstract: Many popular network models rely on the assumption of (vertex) exchangeability, in which the distribution of the graph is invariant to relabelings of the vertices. However, the Aldous-Hoover theorem guarantees that these graphs are dense or empty with probability one, whereas many real-world graphs are sparse. We present an alternative notion of exchangeability for random graphs, which we call edge exchangeability, in which the distribution of a graph sequence is invariant to the order of the edges. We demonstrate that a wide range of edge-exchangeable models, unlike any models that are traditionally vertex-exchangeable, can exhibit sparsity. To develop characterization theorems for edge-exchangeable graphs analogous to the powerful Aldous-Hoover theorem for vertex-exchangeable graphs, we turn to a seemingly different combinatorial problem: clustering. Clustering involves placing entities into mutually exclusive categories. A \"feature allocation\" relaxes the requirement of mutual exclusivity and allows entities to belong simultaneously to multiple categories. In the case of clustering the class of probability distributions over exchangeable partitions of a dataset has been characterized (via \"exchangeable partition probability functions\u201d and the \"Kingman paintbox\"). These characterizations support an elegant nonparametric Bayesian framework for clustering in which the number of clusters is not assumed to be known a priori. We show how these characterizations can be extended to feature allocations and, from there, to edge-exchangeable graphs. \nTamara Broderick \nPrimer: Nonparametric Bayesian Models, methods, and applications \nAbstract: Nonparametric Bayesian methods make use of infinite-dimensional mathematical structures to allow the practitioner to learn more from their data as the size of their data set grows. What does that mean, and how does it work in practice? In this tutorial, we'll cover why machine learning and statistics need more than just parametric Bayesian inference. We'll introduce such foundational nonparametric Bayesian models as the Dirichlet process and Chinese restaurant process and touch on the wide variety of models available in nonparametric Bayes. Along the way, we'll see what exactly nonparametric Bayesian methods are and what they accomplish. \nMay 24, 2017 \nHelmholtz Zentrum M\u00fcnchen, TU Munich \nReconstructing trajectories and branching lineages in single cell genomics \nAbstract: Single-cell technologies have gained popularity in developmental biology because they allow resolving potential heterogeneities due to asynchronicity of differentiating cells. Common data analysis encompasses normalization, followed by dimension reduction and clustering to identify subgroups. However, in the case of cellular differentiation, we may not expect clear clusters to be present - instead cells tend to follow continuous branching lineages. \nIn this talk I will first review methods for pseudotime ordering of cells according to their single cell profiles, which are used for reconstructing such trajectories. Then I will show that modeling the high-dimensional state space as a diffusion process, where cells move to close-by cells with a distance-dependent probability well reflects the differentiating characteristics. Based on the underlying diffusion map transition kernel, cells can be ordered according to a diffusion pseudotime (DPT), which allows for a robust identification of branching decisions and corresponding trajectories of single cells. After application to blood stem cell differentiation, I finish with current extensions towards single cell RNAseq time series and population models as well as driver-gene identification. \nJune 8, 2017 \nCenter for Science and the Imagination, Arizona State University \nWhat Algorithms Want \nAbstract: We depend on \u2014 we believe in \u2014 algorithms to help us get a ride, choose which book to buy, execute a mathematical proof. It is as if we think of code as a magic spell, an incantation to reveal what we need to know and even what we want. But how do we navigate the gap between what algorithms really do and all the things we think, and hope, they do? This talk explores the evolving figure of the algorithm as it bridges the idealized space of computation and messy reality, with unpredictable and sometimes fascinating results. Drawing on sources that range from Neal Stephenson\u2019s \u201cSnow Crash\u201d to Diderot\u2019s \u201cEncyclop\u00e9die,\u201d from Adam Smith to the \u201cStar Trek\u201d computer, Finn explores the gap between theoretical ideas and pragmatic instructions, and the consequences of that gap for research at the intersection of computation and culture. \nFall 2016 Schedule: 8:30am Primer, 9:20am Breakfast, 9:30am Seminar, 10:30am Discussion; all in Monadnock Date Hail Team, Neale Lab, Broad Institute and MGH Introduction to compressed sensing Warren Center for Network and Data Sciences, Math Dept, U Penn Check out Dragonn and DeepLift \nBroad Institute and MIT CSBi \nComposite measurements and molecular compressed sensing for efficient transcriptomics at scale \nAbstract: Comprehensive RNA profiling provides an excellent phenotype of cellular responses and tissue states, but can be prohibitively expensive to generate at the massive scale required for studies of regulatory circuits, genetic states or perturbation screens. However, because expression profiles may reflect a limited number of degrees of freedom, a smaller number of measurements might suffice to capture most of the information. Here, we use existing mathematical guarantees to demonstrate that gene expression information can be preserved in a random low dimensional space. We propose that samples can be directly observed in low dimension through a fundamentally new type of measurement that distributes a single readout across many genes. We show by simulation that as few as 100 of these randomly composed measurements are needed to accurately estimate the global similarity between any pair of samples. Furthermore, we show that methods of compressive sensing can be used to recover gene abundances from drastically under-sampled measurements, even in the absence of any prior knowledge of gene-to-gene correlations. Finally, we propose an experimental scheme for such composite measurements. Thus, compressive sensing and composite measurements can become the basis of a massive scale up in the number of samples that can be profiled, opening new opportunities in the study of single cells, complex tissues, perturbation screens and expression-based diagnostics. \nSeptember 21, 2016 \nColumbia CS \nAutomated Inference and the Promise of Probabilistic Programming \nAbstract: Generative probability models allow us to 1) express assumptions about hidden patterns in data, 2) infer such hidden patterns, and 3) evaluate the accuracy of our findings. However, designing modern models, developing custom inference algorithms, and evaluating accuracy requires enormous effort and cross-disciplinary expertise. Probabilistic programming promises to enable this process by making each step less arduous and more automated. I will begin describing how probabilistic programming can help design modern probability models. I will then focus on automating inference for a wide class of probability models. To this end, I will describe automatic differentiation variational inference, a fully automated approximate inference algorithm. I will demonstrate its application to a mixture modeling analysis of a dataset with millions of observations. I intend to conclude with some thoughts on model evaluation, with a population genetics example. Throughout this talk, I will highlight connections to our software project, Edward : a Python library for probabilistic modeling, inference, and evaluation. \nPrinceton CS \nPrimer: Probabilistic Generative Models and Posterior Inference \nAbstract: To model data we desire to express assumptions about the data, infer hidden structure, make predictions, and simulate new data. In this talk, I will describe how probabilistic generative models provide a common toolkit to meet these challenges. I will first present these ideas in a toy setting followed by discussing the range of probabilistic generative models from structural to algorithmic. Next I will present an in depth view of deep exponential families, a class of probability models containing both predictive and interpretive models. I will end with the central computational problem in realizing the promise of probabilistic generative models: posterior inference. I will demonstrate why deriving inference is tedious and will touch on black box variational methods which seek to alleviate this burden. \nSeptember 28, 2016 \nHarvard School Public Health \nOvercoming Bias and Batch Effects in High-Throughput Data \nAbstract: The unprecedented advance in digital technology during the second half of the 20th century has produced a measurement revolution that is transforming science. In the life sciences, data analysis is now part of practically every research project. Genomics, in particular, is being driven by new measurement technologies that permit us to observe certain molecular entities for the first time. These observations are leading to discoveries analogous to identifying microorganisms and other breakthroughs permitted by the invention of the microscope. An examples of this are the many application of next generation sequencing. Biases, systematic errors and unexpected variability are common in biological data. Failure to discover these problems often leads to flawed analyses and false discoveries. As datasets become larger, the potential of these biases to appear to be significant actually increases. In this talk I will describe several examples of these challenges using very specific examples from gene expression microarrays, RNA-seq, and single-cell assays. I will describe data science solution to these problems. \nHarvard Sys Bio, HST \nPrimer: Experimental and computational techniques underlying RNA-seq \nAbstract: We will provide an overview of the experimental and computational steps involved in RNA-seq for both bulk and single-cell experiments. We will begin with a brief review of Illumina short-read sequencing by synthesis; continue to describing the molecular biology used in preparing RNA-seq libraries; and discuss quality trimming, read alignment, transcript quantification and normalization of gene expression measures. We will conclude with a discussion of techniques commonly leveraged in single-cell RNA-Seq: linear pre-amplification, unique molecular identifiers (UMI/RMTs) and 3\u2019-barcode counting. Throughout the primer, we will mention potential sources of bias that can be introduced at each step and why they occur. \nOctober 12, 2016 \nWarren Center for Network and Data Sciences Complex Systems Group & Department of Mathematics University of Pennsylvania \nWhat can persistent homology see? \nAbstract: The usual framework for TDA takes as its starting point that a data set is sampled (noisily) from a manifold embedded in a high dimensional space, and provides a reconstruction of topological features of that manifold. However, the underlying algebraic topology can be applied to data in a much broader sense, carries much richer information about the system than just the barcodes, and can be fine-tuned so it sees only features of the data we want it to see. I will discuss this framework broadly, with focus on few of these alternative viewpoints, including applications to neuroscience and matrix factorization. \nBroad Institute of MIT and Harvard \nPrimer: What is persistent homology? \nAbstract: A fundamental question in big data analysis is if or how these points may be sampled, noisily, from an intrinsically low-dimensional geometric shape, called a manifold, embedded in a high dimensional \u201csensor\u201d space. Topological data analysis (TDA) aims to measure the \u201cintrinsic shape\u201d of data and identify this manifold despite noise and the likely nonlinear embedding. I will discuss the basics of the fundamental tool in TDA called persistent homology, which assigns to a point cloud a count of topological features \u2013roughly \u201choles\u201d of various dimensions \u2013 with a measure of importance of each feature recorded in a \u201cbarcode\u201d of the data to help distinguish the significant features from the noise. \nOctober 26, 2016 \nHarvard Medical School \nFIDDLE: An integrative deep learning framework for functional genomic data inference \nAbstract: Numerous advances in sequencing technologies have revolutionized genomics through generating many types of genomic functional data. Statistical tools have been developed to analyze individual data types, but there lack strategies to integrate disparate datasets under a unified framework. Moreover, most analysis techniques heavily rely on feature selection and data preprocessing which increase the difficulty of addressing biological questions through the integration of multiple datasets. Here, we introduce FIDDLE (Flexible Integration of Data with Deep LEarning) an open source data-agnostic flexible integrative framework that learns a unified representation from multiple data types to infer another data type. As a case study, we use multiple Saccharomyces cerevisiae genomic datasets to predict global transcription start sites (TSS) through the simulation of TSS-seq data. We demonstrate that a type of data can be inferred from other sources of data types without manually specifying the relevant features and preprocessing. We show that models built from multiple genome-wide datasets perform profoundly better than models built from individual datasets. Thus, FIDDLE learns the complex synergistic relationship within individual datasets and, importantly, across datasets. \nAlex Wiltschko Twitter Cortex \nPrimer: Automatic differentiation, the algorithm behind all deep neural networks \nAbstract: A painful and error-prone step of working with gradient-based models (deep neural networks being one kind) is actually deriving the gradient updates. Deep learning frameworks, like Torch, TensorFlow and Theano, have made this a great deal easier for a limited set of models \u2014 these frameworks save the user from doing any significant calculus by instead forcing the framework developers to do all of it. However, if a user wants to experiment with a new model type, or change some small detail the developers hadn\u2019t planned, they are back to deriving gradients by hand. Fortunately, a 30+ year old idea, called \u201cautomatic differentiation\u201d, and a one year old machine learning-oriented implementation of it, called \u201cautograd\u201d, can bring true and lasting peace to the hearts of model builders. With autograd, building and training even extremely exotic neural networks becomes as easy as describing the architecture. We will also address two practical questions \u2014 \"What's the difference between all these deep learning libraries?\" and \"What does this all mean to me, as a biologist?\" \u2014 as well as providing some detail and historical perspective on the topic of automatic differentiation. \nNovember 2, 2016 \nStanford University \nIntegrative, interpretable deep learning frameworks for regulatory genomics and epigenomics \nAbstract: We present generalizable and interpretable supervised deep learning frameworks to predict regulatory and epigenetic state of putative functional genomic elements by integrating raw DNA sequence with diverse chromatin assays such as ATAC-seq, DNase-seq or MNase-seq. First, we develop novel multi-channel, multi-modal CNNs that integrate DNA sequence and chromatin accessibity profiles (DNase-seq or ATAC-seq) to predict in-vivo binding sites of a diverse set of transcription factors (TF) across cell types with high accuracy. Our integrative models provide significant improvements over other state-of-the-art methods including recently published deep learning TF binding models. Next, we train multi-task, multi-modal deep CNNs to simultaneously predict multiple histone modifications and combinatorial chromatin state at regulatory elements by integrating DNA sequence, RNA-seq and ATAC-seq or a combination of DNase-seq and MNase-seq. Our models achieve high prediction accuracy even across cell-types revealing a fundamental predictive relationship between chromatin architecture and histone modifications. Finally, we develop DeepLIFT (Deep Linear Importance Feature Tracker), a novel interpretation engine for extracting predictive and biological meaningful patterns from deep neural networks (DNNs) for diverse genomic data types. DeepLIFT is the first method that can integrate the combined effects of multiple cooperating filters and compute importance scores accounting for redundant patterns. We apply DeepLIFT on our models to obtain unified TF sequence affinity models, infer high resolution point binding events of TFs, dissect regulatory sequence grammars involving homodimer and heterodimeric binding with co-factors, learn predictive chromatin architectural features and unravel the sequence and architectural heterogeneity of regulatory elements. \nNovember 9, 2016 \nUniversity of Toronto \nAlgorithms for reconstructing tumor evolution \nAbstract: Tumors contain genetically heterogeneous cancerous subpopulations that can differ in their metastatic potential and response to treatment. Our work over the past few years has focused on using computational and statistical methods to reconstruct the phylogeny and the full genotypes of these subpopulations using data from high-throughput sequencing of tumor samples. Tumor subpopulations can be partially characterised by identifying tumor-associated somatic variants using short read sequencing. Subsequent inference of copy number variants or clustering of the variant allele frequencies (VAFs) can reveal the number of major subpopulations present in the tumor as well as the set of mutations which first appear in each subpopulation. Further analysis, and often different data, is needed to determine how the subpopulations relate to one another and whether they share any mutations. Ideally, this analysis would reconstruct the full genotypes of each subpopulation. I will describe my lab\u2019s efforts to recover these full genotypes by reconstructing the tumor\u2019s evolutionary history. We do this by fitting subpopulation phylogenies to the VAFs. In some circumstances, a full reconstruction is possible but often multiple phylogenies are consistent with the data. We have developed a number of methods (PhyloSub, PhyloWGS, treeCRP, PhyloSpan) that use Bayesian inference in non-parametric models to distinguish ambiguous and unambiguous portions of the phylogeny thereby explicitly representing reconstruction uncertainty. Our methods consider both single nucleotide variants as well as copy number variations and adapt to data on pairs of mutations. \nDavid Benjamin Data Sciences & Data Engineering \nPrimer: Intro to Dirichlet Processes \nAbstract: At a mundane level, Dirichlet processes are a clustering algorithm that determines the number of clusters. However, they are also a way to do Bayesian inference on a single infinite model rather than ad hoc model selection on a series of finite models and are the gateway to the field of Bayesian non-parametric models. Many introductions to Dirichlet processes take a formal measure-theoretic approach. In contrast, if you can understand the multinomial distribution you will understand this primer. \nNovember 16, 2016 \nBeck Lab, Harvard Medical School at Beth Israel Deaconess Medical Center \nDeep learning for computational pathology \nAbstract: In this talk, we will provide an introduction to computational pathology, which is an emerging cross-discipline between pathology and computer engineering. Besides, we will introduce a deep learning-based automatic whole slide image analysis system for the identification of cancer metastases in breast sentinel lymph nodes. Our system won the 1st position in the International Challenge: Camelyon16, which was held at the International Symposium on Biomedical Imaging (ISBI) 2016. The system achieved an area under the receiver operating curve (AUC) of 0.925 for the task of whole slide image classification and an average sensitivity of 0.705 for the tumor localization task. A pathologist independently reviewed the same images, obtaining a whole slide image classification AUC of 0.966 and a tumor localization score of 0.733. By combining the predictions from the human pathologist and the automatic analysis system, the performance becomes even higher. These results demonstrate the power of using deep learning to produce significant improvements in the accuracy of pathological diagnoses. \nBeck Lab, Harvard Medical School at Beth Israel Deaconess Medical Center \nPrimer: Practical recommendations for training convolutional neural nets \nAbstract: Deep learning, in particular convolutional neural network (ConvNet), is rapidly emerging as one of the most successful approaches for image and speech recognition. What distinguishes ConvNets and other deep learning systems from conventional machine learning techniques is their ability to learn the entire perception process from end to end. Deep learning systems use multiple nonlinear processing layers to learn useful representations of features directly from data. Searching the parameter space of deep architectures is a complex optimization task. ConvNets can be very sensitive to the setting of their hyper-parameters and network architecture setting. In this talk, I will give practical recommendations for training ConvNets and discuss the motivation and principles behind them. I will also provide recommendations on how to tackle various problems in analyzing medical image data such as lack of data, highly skewed class distributions, etc. Finally, I will introduce some of the advanced ConvNet architectures used in medical image analysis and their suitability for various tasks such as detection, classification, and segmentation. \nDecember 7, 2016 \nProteomics Platform \nSpectral unmixing for next-generation mass spectrometry proteomics \nAbstract: Mass spectrometry proteomics is the method of choice for large-scale quantitation of proteins in biological samples, allowing rapid measurement of the concentrations of thousands of proteins in various modified forms. However, this technique still faces fundamental challenges in terms of reproducibility, bias, and comprehensiveness of proteome coverage. Next-generation mass spectrometry, also known as data-independent acquisition, is a promising new approach with the potential to measure the proteome in a far more comprehensive and reproducible fashion than existing methods, but it has lacked a computational framework suited to the highly convoluted spectra it inherently produces. I will discuss Specter, an algorithm that employs linear unmixing to disambiguate the signals of individual proteins and peptides in next-generation mass spectra. In addition to describing the linear algebra underlying Specter, we'll discuss its implementation in Spark with Python, and see several real datasets to which it's been applied. \nKarsten Krug Proteomics Platform \nPrimer: Mass spectrometry-based proteomics \nAbstract: Mass spectrometry is the workhorse technology to study the abundance and composition of proteins, the key players in every living cell. Within the last decade the technology experienced a revolution in terms of novel instrumentation and optimized sample handling protocols resulting in ever growing numbers of proteins and post-translational modifications that can be routinely studied on a system-wide scale. Briefly, proteins are extracted from cells or tissues and fragmented into smaller peptides. This extremely complex peptide mixture is subjected to liquid chromatography separation and subsequent tandem mass spectrometry analysis in which mass-to-charge ratios of intact peptides and peptide fragments are recorded. Resulting mass spectra are matched to sequence databases or spectral libraries to read out the amino acid sequences and thereby identify the corresponding proteins. The technology is fundamentally different from sequencing-based genomics technology and faces different problems, such as the tremendous dynamic range of protein expression. The instruments can be operated in different acquisition modes for different applications. I will briefly introduce the basics behind discovery or \u2018shotgun\u2019 proteomics, targeted proteomics, data dependent acquisition and data independent acquisition; the latter is a recent and promising development in the proteomics community but poses novel and only partly solved challenges in data analysis. Ryan Peckner will talk about Specter, an approach that tackles this problem using linear algebra. \nDecember 14, 2016 \nHarvard SEAS \nCompiling probabilistic programs \nAbstract: Deriving and implementing an inference algorithm for a probabilistic model can be a difficult and error-prone task. Alternatively, in probabilistic programming, a compiler is used to transform a model into an inference algorithm. In this talk, we'll present probabilistic programming from the perspective of a compiler writer. A compiler for a traditional language uses intermediate languages (ILs) and static analysis to generate efficient code. We'll highlight how these ideas can be used in probabilistic programming for generating flexible and scalable inference algorithms. \nDaniel King Hail Team, Neale Lab \nPrimer: What is a compiler? \nAbstract: A compiler is an algorithm that transforms a source language into a target language. The transformation typically includes an optimizing pass which reduces memory or time requirements. Classic compilers transform languages such as C or Java into near-machine code such as x86 Assembly or JVM Bytecode. Recent work on Domain Specific Languages (DSLs) expands the notion of \"source language\" in order to enable everyone to build easy-to-reason-about abstractions without the performance penalty. In this context, I will discuss compiler design and implementation techniques with examples. \nOn Nov 12, the Broad welcomed a visit from Ryan Adams, a leader in machine learning - a field at the intersection of applied math and computer science that develops models and algorithms to learn from data... \nSpring 2016 Schedule: 8:30am Primer, 9:30am Seminar, 10:30am Discussion in Monadnock Date Hidden Markov models I [ notes ] Hidden Markov models II [ notes ] Linear models I: ordinary least squares Linear models II: regularization and ridge [ ipynb ] Linear models III: regularization, LASSO and sparsity Non-negative matrix factorization (NMF) [ paper ] Convolutional neural nets [ background , paper ] t-dist. stochastic neighbor embedding (t-SNE) [ paper , homepage ] Multiple testing and false discovery rate [ paper ] Tim Poterba, Jon Bloom [ video , outro slides ] Hail Team, Neale Lab Basic introduction to distributed computation [ mapReduce , deepNets , scalingBayes ] \nCofounder, Deep Genomics \nGenomic Medicine: Will Software Eat Bio? \nAbstract: Deep learning will transform biology and medicine, but not in the way that many advocates think. Downloading ten thousand genomes and training a neural network to predict disease won't cut it. It is overly simplistic to believe that deep learning, or machine learning in general, can successfully be applied to genome data without taking into account biological processes that connect genotype to phenotype. The amount of data multiplied by the mutation frequency divided by the biological complexity and the number of hidden variables is too small. I\u2019ll describe a rational \u201csoftware meets bio\u201d approach that has recently emerged in the research community and that is being pursued by dozens of young investigators. The approach has improved our ability to \u201cread the genome\u201d, and I believe it will have a significant impact on genome biology and medicine. I'll discuss which applications are ripe and which are merely seductive, how we should train models to take advantage of new types of data, and how we can interpret machine learning models. \nFebruary 3, 2016 \nResearch Geneticist, Brigham & Women\u2019s Hospital Associate Member, Broad Institute \nJudging the importance of human mutations using evolutionary models \nAbstract: Many forces influence the fate of alleles in populations, and the detailed quantitative description of the allelic dynamics is complex. However, some applications allow for simplifications making the evolutionary models useful in the context of human genetics. The examples include comparative genomics and the analysis of large scale sequencing datasets. \nFebruary 10, 2016 \nDepartment of Systems Biology \nSystems biology: can mathematics lead experiments? \nAbstract: The -omic revolution in biology, and parallel developments in microscopy and imaging, have opened up fascinating new opportunities for analysing biological data using tools from the mathematical sciences. However, the kind of data we have and the way we interpret them are determined by the conceptual landscape through which experimentalists reason about biology. In this talk, I will consider how mathematics can help to shape that conceptual landscape and thereby suggest new experimental strategies. I will describe some of our recent work on how eukaryotic genes are regulated, which tries to update conventional thinking in this field, which is largely derived from bacterial studies, and I will point out how this exercise gives rise to mathematical conjectures for which we currently have no solutions. \nFebruary 17, 2016 \nMIT EECS, IDSS \nGene Regulation in Space and Time \nAbstract: Although the genetic information in each cell within an organism is identical, gene expression varies widely between different cell types. The quest to understand this phenomenon has led to many interesting mathematics problems. First, I will present a new method for learning gene regulatory networks. It overcomes the limitations of existing algorithms for learning directed graphs and is based on algebraic, geometric and combinatorial arguments. Second, I will analyze the hypothesis that the differential gene expression is related to the spatial organization of chromosomes. I will describe a bi-level optimization formulation to find minimal overlap configurations of ellipsoids and model chromosome arrangements. Analyzing the resulting ellipsoid configurations has important implications for the reprogramming of cells during development. \nFebruary 24, 2016 \nUC Berkeley, Department of Statistics \nSparse Inverse Problems \nAbstract: What can we learn by observing nature? How can we understand and predict natural phenomena? This talk is on the mathematics of precision measurement. How can we solve for the input that generated the output of some measurement apparatus? Our starting point is an information theoretic prior of sparsity. We investigate sparse inverse problems where we assume the input can be described by a small number of parameters. We introduce some of our recent theoretical results in superresolution and in spectral clustering. In particular, we show how to solve infinite dimensional deconvolution problems with finite dimensional convex optimization. And we show why dimensionality reduction can be such a useful preprocessing step for mixture models. \nMarch 2, 2016 \nMIT Physics, Health Sciences and Technology \nPolymer models of chromosomes \nAbstract: DNA of the human genome is 2m long and is folded into a structure that fits in a cell nucleus. One of the central physical questions here is the question of scales: How can microscopic processes of molecular interactions of nanometer scale drive chromosomal organization at microns? Inferring principles of 3D organization of chromosomes from a range of biological data is a challenging biophysical problem. We develop a top-down approach to biophysical modeling of chromosomes. Starting with a minimal set of biologically motivated interactions we build polymer models of chromosome organization that can reproduce major features observed in Hi-C and microscopy experiments. I will present our work on modeling organization of human metaphase and interphase chromosomes. \nMarch 9, 2016 \nHarvard School of Public Health, Price Lab \nHaplotype phasing in large cohorts: Modeling, search, or both? \nAbstract: Inferring haploid phase from diploid genotype data -- \"phasing\" for short -- is a fundamental question in human genetics and a key step in genotype imputation. How should one go about phasing a large cohort? The answer depends on how large. In this talk, I will contrast two approaches to computational phasing: hidden Markov models (HMMs), which perform precise but computationally expensive statistical inference, and long-range phasing (LRP), which relies instead on rapidly searching for long genomic segments shared among samples. I will present a new LRP method (Eagle), describe its performance on N=150,000 UK Biobank samples, and discuss future directions. \nMarch 16, 2016 \nJanelia Research Campus, HHMI \nOpen source tools for large-scale neuroscience \nAbstract: Modern computing and the web are both enabling and changing how we do science. Using neuroscience as an example, I will highlight some of these developments, spanning a surprising diversity of technologies. I'll discuss distributed computing for data analytics, cloud computing and containerization for reproducibility, peer-to-peer networks for sharing data and knowledge, functional reactive programming for hardware control, and webgl for large-scale interactive experiments. And I will describe several open source projects we and others are working on across these domains. I hope to convey both what we're learning about the brain with these approaches, and how science itself is evolving in the process. \nMarch 23, 2016 \nGoogle Brain, Google Research Cambridge \nA quick introduction to TensorFlow and related API's \nAbstract: TensorFlow was recently released to the open source world as a platform for developing cutting-edge ML models, with an emphasis on deep architectures including neural nets, convolutional neural nets, recurrent neural nets, and LSTM's. The open source version of TensorFlow now supports distributed computation across many machines, opening up a new level of scale to the research community. In this talk, we'll go over a quick introduction to the basic TensorFlow abstractions, and will also look at some higher-level API's that offer a convenient level of abstraction for many common use cases. Folks interested in learning more are encouraged to visit tensorflow.org , and the excellent Udacity course on ML featuring TensorFlow. \nMarch 30, 2016 \nHarvard Organismic and Evolutionary Biology (Chair) \nThe effects of population pedigrees on gene genealogies \nAbstract: The models of coalescent theory for diploid organisms are wrongly based on averaging over reproductive, or family, relationships. In fact, the entire set of relationships, which may be called the population pedigree, is fixed by past events. Because of this, the standard equations of population genetics for probabilities of common ancestry are incorrect. However, the predictions of coalescent models appear surprisingly accurate for many purposes. A number of different scenarios will be investigated using simulations to illustrate the effects of pedigrees on gene genealogies both within and among loci. These scenarios include selective sweeps, the occurrence of very large families, and population subdivision with migration. \nApril 6, 2016 \nCEO Atomwise \nAtomNet: A Deep Convolutional Neural Network for Bioactivity Prediction in Structure-based Drug Discovery \nAbstract: Deep convolutional neural networks (neural nets with a constrained architecture that leverages the spatial and temporal structure of the domain they model) achieve the best predictive performance in areas such as speech and image recognition. Such neural networks autonomously discover and hierarchically compose simple local features into complex models. We demonstrate that biochemical interactions, being similarly local, are amenable to automatic discovery and modeling by similarly-constrained machine learning architectures. We describe the training of AtomNet, the first structure-based, deep convolutional neural network designed to predict the bioactivity of small molecules for drug discovery applications, on millions of training examples derived from ChEMBL and the PDB. We visualize the automatically-derived convolutional filters and demonstrate that the system is discovering chemically sensible interactions. Finally, we demonstrate the utility of autonomously-discovered filters by outperforming previous docking approaches and achieving an AUC greater than 0.9 on 57.8% of the targets in the DUDE benchmark. In further contrast to existing DNN techniques, we show that AtomNet\u2019s application of local convolutional filters to structural target information successfully predicts new active molecules for targets with no previously known modulators. \nApril 13, 2016 \nCarpenter Lab , Broad Imaging Platform \nInformation in Cell Images: Targeting Diseases and Characterizing Compounds \nAbstract: Our lab, the Broad\u2019s Imaging Platform, aims to make perturbations in cell morphology as computable as other large-scale functional genomics data. We began by creating model-based segmentation algorithms to identify regions of interest in images (usually, individual cells or compartments within them) and produced software that has become the world standard for image analysis from high-throughput microscopy experiments ( CellProfiler , cited in 3000+ scientific papers). We have taken on a new challenge \u2013 using cell images to identify signatures of genes and chemicals, with the ultimate goal of finding the cause and potential cures of diseases. High-throughput microscopy enables imaging several thousand cells per chemical or genetic perturbation, and identifying multiple organelles using fluorescent markers yields hundreds of image features per cell. We use this rich information to construct perturbation signatures or \u201cprofiles\u201d. Our goals in these profiling experiments include identifying drug targets and mechanisms of action, determining the functional impact of disease-related alleles, creating performance-diverse chemical libraries, categorizing mechanisms of drug toxicity, and uncovering diagnostic markers for psychiatric disease.The technical challenges we encounter include dealing with cellular subpopulation heterogeneity, interpreting and visualizing statistical models, learning better representations of the data, and integrating imaging information with other data modalities. \nApril 20, 2016 \nZhang Lab \nDNA microscopy and the sequence-to-image inverse problem \nAbstract: Technologies that jointly resolve both gene sequences and the spatial relationships of the cells that express them are playing an increasing role in deepening our understanding of tissue biology. In this talk, I will describe an experimental technique, called DNA microscopy, which encodes the physical structure and genetic composition of a biological sample directly into a library of DNA sequences. I will then discuss and demonstrate the application of N-body optimization to the inverse problem of inferring positions from real data. \n9:30am, Monadnock, April 27, 2016 \nColumbia University, New York Genome Center \nCompressed Experiments \nAbstract: Molecular biology increasingly relies on large screens where enormous numbers of specimens are systematically assayed in the search for a particular, rare outcome. These screens include the systematic testing of small molecules for potential drugs and testing the association between genetic variation and a phenotype of interest. While these screens are ``hypothesis-free,'' they can be wasteful; pooling the specimens and then testing the pools is more efficient. We articulate in precise mathematical ways the type of structures useful in combinatorial pooling designs so as to eliminate waste, to provide light weight, flexible, and modular designs. We show that Reed-Solomon codes, and more generally linear codes, satisfy all of these mathematical properties. We further demonstrate the power of this technique with Reed-Solomon-based biological experiments. We provide general purpose tools for experimentalists to construct and carry out practical pooling designs with rigorous guarantees for large screens. \n1pm, Yellowstone, April 27, 2016 \nStanford University and U.C. Berkeley \nThe Science of Information: Case Studies in DNA and RNA Assembly \nAbstract: Claude Shannon invented information theory in 1948 to study the fundamental limits of communication. The theory not only establishes the baseline to judge all communication schemes but inspires the design of ones that are simultaneously information optimal and computationally efficient. In this talk, we discuss how this point of view can be applied on the problems of de novo DNA and RNA assembly from shotgun sequencing data. We establish information limits for these problems, and show how efficient assembly algorithms can be designed to attain these information limits, despite the fact that combinatorial optimization formulations of these problems are NP-hard. We discuss Shannon, a de novo RNA-seq assembly software designed based on such principles, and compare its performance against state-of-the-art assemblers on several datasets. \nMay 4, 2016 \nPrinceton University \nBayesian structured sparsity: rethinking sparse regression \nAbstract: Sparse regression has become an indispensable method for data analysis in the last 20 years. The general framework for sparse regression has a number of drawbacks that we and others address in recent methods, including robustness of model selection, issues with correlated predictors, and a test statistic that is based on the size of the effect. All of these issues arise in the context of association mapping of genetic variants to quantitative traits. This talk will discuss one approach to structured sparse regression to mitigate these problems in the context of genome-wide association mapping with quantitative traits using a Gaussian process prior to add structure to the sparsity-inducing prior across predictors. We will also describe ongoing efforts for variants on this model for different analytic purposes, including neuroscience applications, identifying driver somatic mutations in cancer, and methods for causal inference in observational data with large numbers of instruments. \nMay 11, 2016 \nColumbia University \nScaling and Generalizing Variational Inference \nAbstract: Latent variable models have become a key tool for the modern statistician, letting us express complex assumptions about the hidden structures that underlie our data. Latent variable models have been successfully applied in numerous fields. The central computational problem in latent variable modeling is posterior inference, the problem of approximating the conditional distribution of the latent variables given the observations. Posterior inference is central to both exploratory tasks and predictive tasks. Approximate posterior inference algorithms have revolutionized Bayesian statistics, revealing its potential as a usable and general-purpose language for data analysis. Bayesian statistics, however, has not yet reached this potential. First, statisticians and scientists regularly encounter massive data sets, but existing approximate inference algorithms do not scale well. Second, most approximate inference algorithms are not generic; each must be adapted to the specific model at hand. In this talk I will discuss our recent research on addressing these two limitations. I will describe stochastic variational inference, an approximate inference algorithm for handling massive data sets. I will demonstrate its application in genetics to the STRUCTURE model of Pritchard et al., 2000. Then I will discuss black box variational inference. Black box inference is a generic algorithm for approximating the posterior. We can easily apply it to many models with little model-specific derivation and few restrictions on their properties. I will demonstrate how we can use black box inference to develop new software tools for probabilistic modeling. \nMay 18, 2016 \nMIT CSAIL, EECS; Co-founder, CTO Databricks \nScaling data analysis with Apache Spark \nAbstract: [we neglected to request an abstract but are confident the speaker knows something about Spark] \nJune 1, 2016 \nUniversity of Washington, CS, EE and Genome Sciences \nIdentifying molecular markers for cancer treatment from big data \nAbstract: The repertoire of drugs for patients with cancer is rapidly expanding, however cancers that appear pathologically similar often respond differently to the same drug regimens. Methods to better match patients to specific drugs are in high demand. For example, patients over 65 with acute myeloid leukemia (AML), an aggressive blood cancer, have no better prognosis today than they did in 1980. For a growing number of diseases, there is a fair amount of data on molecular profiles from patients. The most important step necessary to realize the ultimate goal is to identify molecular markers in these data that predict treatment outcomes, such as response to each chemotherapy drug. However, due to the high-dimensionality (i.e., the number of variables is much greater than the number of samples) along with potential biological or experimental confounders, it is an open challenge to identify robust biomarkers that are replicated across different studies. In this talk, I will present two novel machine learning algorithms to resolve these challenges. These methods learn the low-dimensional features that are likely to represent important molecular events in the disease process in an unsupervised fashion, based on molecular profiles from multiple populations of cancer patients. These algorithms led to the identification of novel molecular markers in AML and ovarian cancer. MIA", "highlightText": "", "highlightTitle": "", "language": "english", "external_links": [], "entities": {"persons": [{"name": "afonso bandeira", "sentiment": "none"}, {"name": "alex bloemendal", "sentiment": "none"}, {"name": "john", "sentiment": "none"}, {"name": "shannon", "sentiment": "none"}, {"name": "suvrit sra", "sentiment": "none"}, {"name": "pritchard", "sentiment": "none"}, {"name": "michael rooney", "sentiment": "none"}, {"name": "yakir reshef", "sentiment": "none"}, {"name": "david rolnick", "sentiment": "none"}, {"name": "eric lander", "sentiment": "none"}, {"name": "gene", "sentiment": "none"}, {"name": "hail team", "sentiment": "none"}, {"name": "hilary finucane", "sentiment": "none"}, {"name": "daniel king hail team", "sentiment": "none"}, {"name": "debora", "sentiment": "none"}, {"name": "beck lab", "sentiment": "none"}, {"name": "python", "sentiment": "none"}, {"name": "kharchenko", "sentiment": "none"}, {"name": "alex wiltschko", "sentiment": "none"}, {"name": "ryan peckner", "sentiment": "none"}, {"name": "ryan adams", "sentiment": "none"}, {"name": "matei zaharia", "sentiment": "none"}, {"name": "ann sizemore", "sentiment": "none"}, {"name": "adam smith", "sentiment": "none"}, {"name": "wigner", "sentiment": "none"}, {"name": "karsten krug", "sentiment": "none"}, {"name": "ion stoica", "sentiment": "none"}, {"name": "nick patterson", "sentiment": "none"}, {"name": "adam", "sentiment": "none"}, {"name": "diderot", "sentiment": "none"}, {"name": "carl de boer", "sentiment": "none"}, {"name": "aviv regev", "sentiment": "none"}, {"name": "regev lab", "sentiment": "none"}, {"name": "helmholtz zentrum m\u00fcnchen", "sentiment": "none"}, {"name": "basset", "sentiment": "none"}, {"name": "finn", "sentiment": "none"}, {"name": "anthony phillipakis", "sentiment": "none"}, {"name": "hacohen lab", "sentiment": "none"}, {"name": "edward", "sentiment": "none"}, {"name": "neal stephenson", "sentiment": "none"}, {"name": "alex wein", "sentiment": "none"}, {"name": "ankur moitra", "sentiment": "none"}, {"name": "tim poterba", "sentiment": "none"}, {"name": "chengtao li", "sentiment": "none"}, {"name": "bertrand haas", "sentiment": "none"}, {"name": "tensorflow", "sentiment": "none"}, {"name": "tamara broderick", "sentiment": "none"}, {"name": "david benjamin", "sentiment": "none"}, {"name": "specter", "sentiment": "none"}, {"name": "markov", "sentiment": "none"}, {"name": "bayes", "sentiment": "none"}, {"name": "jon bloom", "sentiment": "none"}, {"name": "claude shannon", "sentiment": "none"}, {"name": "yossi farjoun", "sentiment": "none"}, {"name": "regev lab kharchenko lab", "sentiment": "none"}], "organizations": [{"name": "inference & algorithms", "sentiment": "negative"}, {"name": "inference & algorithms home models", "sentiment": "negative"}, {"name": "inference & algorithms  models", "sentiment": "neutral"}, {"name": "project rephetio & hetionet", "sentiment": "none"}, {"name": "cto databricks  scaling", "sentiment": "none"}, {"name": "stat math reading club", "sentiment": "none"}, {"name": "harvard medical school  from", "sentiment": "none"}, {"name": "lrp", "sentiment": "none"}, {"name": "department of systems biology", "sentiment": "none"}, {"name": "harvard chemistry", "sentiment": "none"}, {"name": "new york genome center", "sentiment": "none"}, {"name": "u.c. berkeley", "sentiment": "none"}, {"name": "finucane lab", "sentiment": "none"}, {"name": "harvard medical school", "sentiment": "none"}, {"name": "data sciences & data engineering", "sentiment": "none"}, {"name": "research geneticist", "sentiment": "none"}, {"name": "wellcome trust centre for human genetics", "sentiment": "none"}, {"name": "genome sciences  identifying", "sentiment": "none"}, {"name": "penn school of medicine", "sentiment": "none"}, {"name": "illumina", "sentiment": "none"}, {"name": "eagle", "sentiment": "none"}, {"name": "warren center for network and data sciences", "sentiment": "none"}, {"name": "aml", "sentiment": "none"}, {"name": "mit physics", "sentiment": "none"}, {"name": "price lab  haplotype", "sentiment": "none"}, {"name": "princeton", "sentiment": "none"}, {"name": "mgh introduction", "sentiment": "none"}, {"name": "smrc", "sentiment": "none"}, {"name": "broad institute", "sentiment": "none"}, {"name": "mit statistics  learning", "sentiment": "none"}, {"name": "pca", "sentiment": "none"}, {"name": "department of systems biology  systems", "sentiment": "none"}, {"name": "columbia university", "sentiment": "none"}, {"name": "samuel lee data sciences & data engineering", "sentiment": "none"}, {"name": "oxford  simulating", "sentiment": "none"}, {"name": "biomedical imaging", "sentiment": "none"}, {"name": "mit", "sentiment": "none"}, {"name": "deeplift  broad institute", "sentiment": "none"}, {"name": "warren center for network and data sciences complex systems group & department of mathematics university of pennsylvania", "sentiment": "none"}, {"name": "beth israel deaconess medical center  deep", "sentiment": "none"}, {"name": "beth israel deaconess medical center", "sentiment": "none"}, {"name": "university of toronto  algorithms", "sentiment": "none"}, {"name": "broad institute  learning", "sentiment": "none"}, {"name": "broad institute  grand challenge", "sentiment": "none"}, {"name": "broad institute of mit", "sentiment": "none"}, {"name": "harvard cs", "sentiment": "none"}, {"name": "harvard sys bio", "sentiment": "none"}, {"name": "tda", "sentiment": "none"}, {"name": "harvard", "sentiment": "none"}, {"name": "isbi", "sentiment": "none"}, {"name": "harvard organismic", "sentiment": "none"}, {"name": "harvard school of public health", "sentiment": "none"}, {"name": "department of biomedical informatics", "sentiment": "none"}, {"name": "tu munich  reconstructing", "sentiment": "none"}, {"name": "brigham & women\u2019s hospital", "sentiment": "none"}, {"name": "chemical biology & therapeutic sciences  continuous", "sentiment": "none"}, {"name": "faculty", "sentiment": "none"}, {"name": "broad\u2019s imaging platform", "sentiment": "none"}, {"name": "samuel friedman broad data sciences", "sentiment": "none"}, {"name": "stanford university", "sentiment": "none"}, {"name": "lstm", "sentiment": "none"}, {"name": "princeton university  bayesian", "sentiment": "none"}, {"name": "hubble space telescope", "sentiment": "none"}, {"name": "david benjamin data sciences & data engineering", "sentiment": "none"}, {"name": "neale lab", "sentiment": "none"}, {"name": "mgh", "sentiment": "none"}, {"name": "columbia cs  automated inference", "sentiment": "none"}, {"name": "cs", "sentiment": "none"}, {"name": "health sciences and technology  polymer", "sentiment": "none"}, {"name": "columbia university  scaling", "sentiment": "none"}, {"name": "stanford university  integrative", "sentiment": "none"}, {"name": "university of washington", "sentiment": "none"}, {"name": "greene lab", "sentiment": "none"}, {"name": "arizona state university", "sentiment": "none"}, {"name": "u penn check", "sentiment": "none"}, {"name": "harvard school public health  overcoming bias", "sentiment": "none"}, {"name": "google research cambridge", "sentiment": "none"}, {"name": "data sciences platform", "sentiment": "none"}, {"name": "uc berkeley", "sentiment": "none"}, {"name": "uk biobank", "sentiment": "none"}, {"name": "harvard medical school  structure", "sentiment": "none"}], "locations": [{"name": "columbia", "sentiment": "none"}, {"name": "yellowstone", "sentiment": "none"}, {"name": "kingman", "sentiment": "none"}, {"name": "greka lab", "sentiment": "none"}, {"name": "boston", "sentiment": "none"}]}, "rating": null, "crawled": "2017-10-16T20:22:40.000+03:00"}, {"thread": {"uuid": "a7f348023d652df8c2f2c8abfd81be833eb99385", "url": "http://omgili.com/ri/.wHSUbtEfZShuqU8OSon1xB4C1imBQp0uCXKWA0r6sM1Ohl5quPSRaA67c7FuIy4yMN4d0XmdGwyCtuBVl7_wR25l9Eu2281raW3fEUkqifVWmxwj8W.J68LzFql5IR.xy2PinPYXQysod5CNugY1Q--", "site_full": "www.broadinstitute.org", "site": "broadinstitute.org", "site_section": "https://www.broadinstitute.org/rss.xml", "site_categories": ["health"], "section_title": "Broad Institute", "title": "Looking across species for the genetics underlying obsessive-compulsive disorder", "title_full": "Looking across species for the genetics underlying obsessive-compulsive disorder", "published": "2017-10-17T18:15:00.000+03:00", "replies_count": 0, "participants_count": 1, "site_type": "news", "country": "US", "spam_score": 0.0, "main_image": "", "performance_score": 0, "domain_rank": 45479, "social": {"facebook": {"likes": 0, "comments": 0, "shares": 0}, "gplus": {"shares": 0}, "pinterest": {"shares": 0}, "linkedin": {"shares": 0}, "stumbledupon": {"shares": 0}, "vk": {"shares": 0}}}, "uuid": "a7f348023d652df8c2f2c8abfd81be833eb99385", "url": "http://omgili.com/ri/.wHSUbtEfZShuqU8OSon1xB4C1imBQp0uCXKWA0r6sM1Ohl5quPSRaA67c7FuIy4yMN4d0XmdGwyCtuBVl7_wR25l9Eu2281raW3fEUkqifVWmxwj8W.J68LzFql5IR.xy2PinPYXQysod5CNugY1Q--", "ord_in_thread": 0, "author": "kzusi@broadinstitute.org", "published": "2017-10-17T18:15:00.000+03:00", "title": "Looking across species for the genetics underlying obsessive-compulsive disorder", "text": "Looking across species for the genetics underlying obsessive-compulsive disorder Credit : Susanna M. Hamilton, Broad Communications By Karen Zusi \nGuided by a multispecies comparison between dogs, mice, and humans, researchers identify new genes and biological pathways associated with OCD. \nObsessive-compulsive disorder (OCD) is a hereditary disorder that affects roughly 80 million people worldwide, but the biology of the disease is poorly understood. The frontline therapeutics, which target serotonin signaling in the brain, only work in a narrow subset of patients. \nIn a new effort to dig into the biology of OCD, a team led by Broad Institute researchers compared genetic information across multiple species that suffer from compulsive behavior disorders and identified four novel genes with OCD-associated variants in humans. The genes are involved in synapse maintenance and neurotransmitter signaling, suggesting potential mechanisms at work in the disorder. The research was published today in Nature Communications . \nThe researchers \u2014 led by postdoctoral associate Hyun Ji Noh and co-senior authors Kerstin Lindblad-Toh , senior science director of Broad\u2019s Vertebrate Genomics group and professor at Uppsala University, and Elinor Karlsson , director of the Vertebrate Genomics group and assistant professor at the University of Massachusetts Medical School \u2014 initially compiled a list of genetic associations from previous studies of human OCD and co-morbid disorders, mouse compulsive behavior models, and canine compulsive disorder (CD). Canine CD, prevalent in certain dog breeds, often manifests as excessive licking, sucking, or tail-chasing. \nThe team used this data to refine a list of more than 600 genes and 80,000 related regulatory elements that might be involved in human OCD. \u201cWe were seeking ways to take advantage of information from other species in order to inform and focus the study in humans,\u201d explained Noh. \u201cEach additional species that we looked at gave us more information about possible factors in the brain that contribute to OCD.\u201d \nThe researchers designed targeted sequencing panels for these genes and examined them in two human cohorts, totaling more than 1,300 cases and 1,600 controls. Ultimately, the team identified four genes \u2014 NRXN1 , HTR2A , CTTNBP2 , and REEP3 , all expressed in the brain \u2014 that had variants in either protein-coding or regulatory DNA significantly associated with human OCD. \nNRXN1 \u2019s association was further supported using population-matched data from the Exome Aggregation Database as an additional set of controls. In follow-up experiments to investigate regulatory variants in CTTNBP2 and REEP3 , the researchers introduced the regulatory DNA elements with mutations into human cells and observed changes in transcription factor binding, providing evidence for a mechanistic role in the cell. \nVariants of the four genes are predicted to disrupt synapse development and throw neural pathways, including serotonin and glutamate signaling, out of balance in brain regions previously implicated in OCD. NRXN1 , involved in synapse structure, and REEP3 , which encodes a protein that shapes membranes within certain cells, have also been highlighted in studies of autism spectrum disorder. The data suggest new targets to pursue for an improved biological and therapeutic understanding of OCD. \nThis study was supported in part by a Broad Institute SPARC ( Scientific Projects to Accelerate Research and Collaboration ) grant. Additional funding was provided by the National Institute of Mental Health (1R21MH109938\u00ad01), AKC Health Foundation, Swedish Research Council, Swedish Medical Research Council, and European Research Council. Paper(s) cited:", "highlightText": "", "highlightTitle": "", "language": "english", "external_links": [], "entities": {"persons": [{"name": "susanna m.", "sentiment": "neutral"}, {"name": "kerstin lindblad-toh", "sentiment": "none"}, {"name": "noh", "sentiment": "none"}, {"name": "hamilton", "sentiment": "none"}, {"name": "elinor karlsson", "sentiment": "none"}, {"name": "hyun ji noh", "sentiment": "none"}, {"name": "karen zusi", "sentiment": "none"}], "organizations": [{"name": "university of massachusetts medical school", "sentiment": "none"}, {"name": "vertebrate genomics", "sentiment": "none"}, {"name": "uppsala university", "sentiment": "none"}, {"name": "swedish research council", "sentiment": "none"}, {"name": "broad institute", "sentiment": "none"}, {"name": "broad institute sparc", "sentiment": "none"}, {"name": "broad communications", "sentiment": "none"}, {"name": "broad\u2019s vertebrate genomics", "sentiment": "none"}, {"name": "nature communications", "sentiment": "none"}, {"name": "european research council", "sentiment": "none"}, {"name": "akc health foundation", "sentiment": "none"}, {"name": "swedish medical research council", "sentiment": "none"}, {"name": "national institute of mental health", "sentiment": "none"}], "locations": []}, "rating": null, "crawled": "2017-10-18T02:44:43.000+03:00"}, {"thread": {"uuid": "042a9517097f15245fbc0deb01147651e8628c47", "url": "http://omgili.com/ri/.wHSUbtEfZShuqU8OSon1xB4C1imBQp0uCXKWA0r6sN0Nf7MDtMql3Nnyz3Pk16cWUQPZFHancdMrcMRH8YzsY5YEJDMHoL434zV4A3W83gQ77SRcVC16C6OZBHqUZ8brz5ggpQ3m7zQxgIINfWLeqKYdZgVWnInYl8g9OHakRjvWACgJtLqSg--", "site_full": "www.broadinstitute.org", "site": "broadinstitute.org", "site_section": "https://www.broadinstitute.org/rss.xml", "site_categories": ["health"], "section_title": "Broad Institute", "title": "DuPont Pioneer and Broad Institute Join Forces to Enable Democratic CRISPR Licensing in Agriculture", "title_full": "DuPont Pioneer and Broad Institute Join Forces to Enable Democratic CRISPR Licensing in Agriculture", "published": "2017-10-18T07:00:00.000+03:00", "replies_count": 0, "participants_count": 1, "site_type": "news", "country": "US", "spam_score": 0.0, "main_image": "", "performance_score": 0, "domain_rank": 45479, "social": {"facebook": {"likes": 0, "comments": 0, "shares": 0}, "gplus": {"shares": 0}, "pinterest": {"shares": 0}, "linkedin": {"shares": 0}, "stumbledupon": {"shares": 0}, "vk": {"shares": 0}}}, "uuid": "042a9517097f15245fbc0deb01147651e8628c47", "url": "http://omgili.com/ri/.wHSUbtEfZShuqU8OSon1xB4C1imBQp0uCXKWA0r6sN0Nf7MDtMql3Nnyz3Pk16cWUQPZFHancdMrcMRH8YzsY5YEJDMHoL434zV4A3W83gQ77SRcVC16C6OZBHqUZ8brz5ggpQ3m7zQxgIINfWLeqKYdZgVWnInYl8g9OHakRjvWACgJtLqSg--", "ord_in_thread": 0, "author": "David Cameron", "published": "2017-10-18T07:00:00.000+03:00", "title": "DuPont Pioneer and Broad Institute Join Forces to Enable Democratic CRISPR Licensing in Agriculture", "text": "DuPont Pioneer and Broad Institute Join Forces to Enable Democratic CRISPR Licensing in Agriculture Credit : iStock/Rasica By David Cameron \nNew partnership provides nonexclusive licenses to CRISPR-Cas9 IP for commercial agricultural research \nDuPont Pioneer and   Harvard announced today that they have reached an agreement to jointly provide non-exclusive licenses to foundational CRISPR-Cas9 intellectual property under their respective control for use in commercial agricultural research and product development. These two major CRISPR-Cas9 license holders are coming together with the shared goal of enabling all entities wanting to apply the technology for agricultural applications with a full range of CRISPR-Cas9 tools. Such foundational intellectual property (IP) for CRISPR-Cas9 technology   to universities and nonprofit organizations for academic research. Pioneer is a business unit of the Agriculture Division of DowDuPont\u2122. \n\u201cThe promise of CRISPR-Cas9 technology in the hands of many will result in a wide array of benefits for the global food supply ranging from higher and more stable yields of grains, fruits and vegetables for farmers; more nutritious, healthier and affordable foods for consumers; and, improved sustainability of agricultural systems for society,\u201d said Neal Gutterson, vice president of Research & Development at DuPont Pioneer. \u201cIt is profoundly important to ensure that this technology is made widely available for agriculture. By partnering with the Broad Institute, together we can maximize access to CRISPR-Cas9 around the world for the greater good.\u201d \n\u201cWhen DuPont Pioneer initially approached us to secure a license for commercial research, we both saw a unique opportunity to provide much broader access to the technology for agriculture,\u201d said Eric Lander, president and founding director of the Broad Institute. \u201cWe applaud DuPont Pioneer for its commitment to advancing research and commercialization to accelerate progress in agriculture.\u201d \nThe complex CRISPR licensing landscape includes patents and patent applications from multiple parties. Entities often desire access to comprehensive IP, to ensure their ability to apply the scientific tools as widely as possible. To enable such access, Pioneer and Broad Institute have agreed on a joint non-exclusive licensing framework for agricultural use that (i) continues to provide non-exclusive access to IP from Broad Institute co-owned with its collaborators (including Harvard University, the   Technology, New York Genome Center, New York University, The Rockefeller University, and the University of Iowa), and (ii) provides non-exclusive access to foundational IP from Pioneer and to IP from the licenses that Pioneer gained access through Caribou Biosciences , ERS Genomics and Vilnius University . License limitations exclude certain CRISPR technology applications, including for gene drive or tobacco products for human use. \nBroad and Pioneer continue to retain the right to grant independent, non-exclusive licenses for the CRISPR-Cas9 IP that each institution controls to any interested entity. \nTo inquire about a license, commercial users should email Pioneer at or visit the Broad website or contact . Academic and nonprofit researchers do not require a license to use the technology for research. \nLearn more about CRISPR-Cas applications in agriculture at http://crisprcas.pioneer.com \nLearn more about the Broad Institute\u2019s efforts to offer CRISPR tools for agriculture on the Broad website .", "highlightText": "", "highlightTitle": "", "language": "english", "external_links": [], "entities": {"persons": [{"name": "eric lander", "sentiment": "none"}, {"name": "neal gutterson", "sentiment": "none"}, {"name": "david cameron  new", "sentiment": "none"}], "organizations": [{"name": "dupont pioneer and broad institute join forces to enable democratic crispr licensing in agriculture dupont pioneer and broad institute join forces", "sentiment": "negative"}, {"name": "university of iowa", "sentiment": "none"}, {"name": "broad institute of mit", "sentiment": "none"}, {"name": "ers genomics", "sentiment": "none"}, {"name": "research & development", "sentiment": "none"}, {"name": "vilnius university", "sentiment": "none"}, {"name": "harvard university", "sentiment": "none"}, {"name": "broad institute", "sentiment": "none"}, {"name": "dupont pioneer", "sentiment": "none"}, {"name": "new york genome center", "sentiment": "none"}, {"name": "massachusetts institute of technology", "sentiment": "none"}, {"name": "harvard", "sentiment": "none"}, {"name": "caribou biosciences", "sentiment": "none"}, {"name": "agriculture division", "sentiment": "none"}, {"name": "pioneer", "sentiment": "none"}, {"name": "pioneer and broad institute", "sentiment": "none"}, {"name": "new york university", "sentiment": "none"}, {"name": "rockefeller university", "sentiment": "none"}], "locations": []}, "rating": null, "crawled": "2017-10-18T15:27:46.009+03:00"}, {"thread": {"uuid": "254bb711e804bd70a76a7d3165a4c4d88fd90fa8", "url": "http://omgili.com/ri/.wHSUbtEfZShuqU8OSon1xB4C1imBQp0uCXKWA0r6sN3SkGVnrqdd0ijp5kYJg.gugY5DMAG0MhMR9QpKvDABt_2IDC4eieO8POHRiT0qI7SDlgTgczcJ0DstgNJzXD1", "site_full": "www.broadinstitute.org", "site": "broadinstitute.org", "site_section": "https://www.broadinstitute.org/rss.xml", "site_categories": ["health"], "section_title": "Broad Institute", "title": "Removing a major CRISPR licensing roadblock in agriculture", "title_full": "Removing a major CRISPR licensing roadblock in agriculture", "published": "2017-10-18T07:00:00.000+03:00", "replies_count": 0, "participants_count": 1, "site_type": "news", "country": "US", "spam_score": 0.0, "main_image": "", "performance_score": 0, "domain_rank": 45479, "social": {"facebook": {"likes": 0, "comments": 0, "shares": 0}, "gplus": {"shares": 0}, "pinterest": {"shares": 0}, "linkedin": {"shares": 0}, "stumbledupon": {"shares": 0}, "vk": {"shares": 0}}}, "uuid": "254bb711e804bd70a76a7d3165a4c4d88fd90fa8", "url": "http://omgili.com/ri/.wHSUbtEfZShuqU8OSon1xB4C1imBQp0uCXKWA0r6sN3SkGVnrqdd0ijp5kYJg.gugY5DMAG0MhMR9QpKvDABt_2IDC4eieO8POHRiT0qI7SDlgTgczcJ0DstgNJzXD1", "ord_in_thread": 0, "author": "rcirceo@broadinstitute.org", "published": "2017-10-18T07:00:00.000+03:00", "title": "Removing a major CRISPR licensing roadblock in agriculture", "text": "Removing a major CRISPR licensing roadblock in agriculture Credit : iStock/stevanovicigor By Issi Rozen, Chief Business Officer \nThe Broad Institute of MIT and Harvard announced an agreement that removes a major roadblock that had threatened to limit the potential of CRISPR-Cas9 genome editing to dramatically advance agriculture. \nToday   Harvard announced an agreement that removes a major roadblock that had threatened to limit the potential of CRISPR-Cas9 genome editing to dramatically advance agriculture. \nAs outlined in our press release , Broad and DuPont Pioneer have agreed to create a joint licensing framework for the use of CRISPR-Cas9 technology in agriculture. Specifically, we\u2019ve agreed to jointly provide non-exclusive licenses to intellectual property for use in commercial agricultural research and product development. Just as important, all of the intellectual property   for academic research. The goal is to ensure that scientists in both academia and industry will be able to use CRISPR-Cas9 technology to explore new ways to lift crop yields, improve drought resistance, and reduce reliance on pesticides. \nWhat made this possible? \nIt worked because the two organizations that controlled the licensing of much of the foundational CRISPR-Cas9 intellectual property for use in agriculture decided to work together to make these tools available non-exclusively. The Broad and its collaborators (including Harvard University, the   Technology, New York Genome Center, New York University, The Rockefeller University, and the University of Iowa) control one large collection of CRISPR-Cas9 IP. The Broad had already made this IP (i) freely available for all academic and non-profit research for all uses and (ii) available for non-exclusive licensing for commercial use in agriculture. Pioneer has exclusive rights for use in agriculture to another set of CRISPR patents and patent applications. (Details for those who may be interested: The University of California-Berkeley (UCB) exclusively licensed its CRISPR patents and those of University of Vienna to UCB\u2019s spin-off, Caribou Biosciences. In turn, Caribou licensed these rights for agriculture to Pioneer, together with rights in applications filed by Caribou. Pioneer also obtained an exclusive license to the companion rights of Emmanuelle Charpentier (that had been exclusively licensed to her spin-off, ERS Genomics) in the joint applications filed by the UCB. Separately, Pioneer licensed exclusive rights to issued patents and patent applications from Vilnius University in Lithuania, whose intellectual property overlaps that of UCB. Finally, Pioneer has its own patents and patent applications.) To maximize the scientific impact of CRISPR-Cas9 for improving agriculture, it was important to ensure that agriculture companies had access to all of the genome editing tools covered under these patents and patent claims. Yet, they had no clear path to obtaining licenses to the exclusive portions of the IP. \nWhen Pioneer approached the Broad about gaining access to Broad\u2019s IP, the two organizations came up with a creative solution: (i) Broad would provide Pioneer with a non-exclusive license to Broad\u2019s IP, and (ii) Pioneer would join Broad in providing non-exclusive licenses to the IP it controlled, as well as making the IP freely available to academic and non-profit researchers. \nNotably, the joint license adheres to the Broad Institute\u2019s ethical restrictions for agricultural use , which prohibit using CRISPR for gene drive, sterile seeds, or tobacco products for human use. \nThis resolves a licensing roadblock that had threatened to limit the potential of CRISPR-Cas9 in agriculture. \nThere remain, of course, roadblocks in other fields of CRISPR use. \nFor all commercial research, Broad offers licenses non-exclusively. However, not all IP-holders do so. \nFor use to develop human therapeutics, Broad decided to grant a license with exclusivity limited by an Inclusive Innovation model , because we judged that some exclusivity would be needed to incent the large investments needed to develop CRISPR technology to the point that it could be used to create medicines to benefit patients. \nIn July, Broad applied to join a worldwide patent pool , run by an independent third party, in an effort to help coordinate licenses with others. \nOur hope is that more organizations will come together in meaningful ways to remove roadblocks and benefit the public.", "highlightText": "", "highlightTitle": "", "language": "english", "external_links": [], "entities": {"persons": [{"name": "issi ro", "sentiment": "negative"}, {"name": "emmanuelle charpentier", "sentiment": "none"}], "organizations": [{"name": "university of iowa", "sentiment": "none"}, {"name": "broad institute of mit", "sentiment": "none"}, {"name": "ers genomics", "sentiment": "none"}, {"name": "vilnius university", "sentiment": "none"}, {"name": "harvard university", "sentiment": "none"}, {"name": "university of california-berkeley", "sentiment": "none"}, {"name": "broad institute", "sentiment": "none"}, {"name": "dupont pioneer", "sentiment": "none"}, {"name": "new york genome center", "sentiment": "none"}, {"name": "massachusetts institute of technology", "sentiment": "none"}, {"name": "harvard", "sentiment": "none"}, {"name": "caribou biosciences", "sentiment": "none"}, {"name": "ucb", "sentiment": "none"}, {"name": "pioneer", "sentiment": "none"}, {"name": "university of vienna", "sentiment": "none"}, {"name": "new york university", "sentiment": "none"}, {"name": "rockefeller university", "sentiment": "none"}], "locations": [{"name": "lithuania", "sentiment": "none"}]}, "rating": null, "crawled": "2017-10-18T15:27:51.003+03:00"}, {"thread": {"uuid": "3c1faddffc318d0538fc1abb92a8a2c00d0de720", "url": "http://omgili.com/ri/.wHSUbtEfZShuqU8OSon1xB4C1imBQp0uCXKWA0r6sNr86NTdtxCtialPzrZ4T2NmOzM.o0Kc5OJvls5peprxXxvzkr14h8CArL6vp5DarPhQZct9yHQCYo00RUVy81kv26oi0IEQkrGCHPAPYBIRLX8G8UHejv4GOi1qpeozkZGE1wsVjgMdA--", "site_full": "www.broadinstitute.org", "site": "broadinstitute.org", "site_section": "https://www.broadinstitute.org/rss.xml", "site_categories": ["health"], "section_title": "Broad Institute", "title": "The international Human Cell Atlas publishes strategic blueprint; announces data from first one million cells", "title_full": "The international Human Cell Atlas publishes strategic blueprint; announces data from first one million cells", "published": "2017-10-18T16:30:00.000+03:00", "replies_count": 0, "participants_count": 1, "site_type": "news", "country": "US", "spam_score": 0.0, "main_image": "", "performance_score": 0, "domain_rank": 45479, "social": {"facebook": {"likes": 0, "comments": 0, "shares": 0}, "gplus": {"shares": 0}, "pinterest": {"shares": 0}, "linkedin": {"shares": 0}, "stumbledupon": {"shares": 0}, "vk": {"shares": 0}}}, "uuid": "3c1faddffc318d0538fc1abb92a8a2c00d0de720", "url": "http://omgili.com/ri/.wHSUbtEfZShuqU8OSon1xB4C1imBQp0uCXKWA0r6sNr86NTdtxCtialPzrZ4T2NmOzM.o0Kc5OJvls5peprxXxvzkr14h8CArL6vp5DarPhQZct9yHQCYo00RUVy81kv26oi0IEQkrGCHPAPYBIRLX8G8UHejv4GOi1qpeozkZGE1wsVjgMdA--", "ord_in_thread": 0, "author": "tulrich@broadinstitute.org", "published": "2017-10-18T16:30:00.000+03:00", "title": "The international Human Cell Atlas publishes strategic blueprint; announces data from first one million cells", "text": "The international Human Cell Atlas publishes strategic blueprint; announces data from first one million cells By Broad Communications \nBlueprint describes path forward for cataloging every cell in the human body; cell data release to be available to research community. The Human Cell Atlas (HCA) Consortium has released a blueprint for the international initiative\u2019s efforts to create a comprehensive reference map of all human cells, a project that will form the basis for a deeper understanding of human health and for diagnosing, monitoring, and treating disease. The blueprint\u2019s release \u2014 posted as a white paper to the HCA website \u2014 coincides with the publication of a Nature commentary by the HCA organizing committee summarizing the consortium\u2019s vision and mission. In addition, the consortium today also announced the impending release of gene expression profiles from the first one million immune cells collected under the HCA, toward an initial milestone of collecting at least 30 million cells representing several tissues and organs for the atlas\u2019 first draft. These data, to be posted on an online repository by early November,   for researchers\u2019 use. The blueprint and data release were presented at the second HCA General Meeting , hosted by the Weizmann Institute of Science in Rehovot, Israel. The meeting celebrates the consortium\u2019s one-year anniversary and marks its official transition from its planning to its operational phase. (Videos of the meeting\u2019s plenary sessions can be found on the HCA YouTube channel .) \u201cOver the past year, the international scientific community, from physicians to computer scientists, has engaged in an open process to plan how to go about making this revolutionary atlas,\u201d said Aviv Regev , a core member, chair of faculty, and director of the Klarman Cell Observatory and Cell Circuits Program at   Harvard; an HHMI Investigator; professor of biology at   Technology; and co-chair, with Sarah Teichmann of the Wellcome Trust Sanger Institute, of the HCA Organizing Committee . \u201cTogether, we\u2019ve drawn the blueprint. Now it\u2019s time to start building the house.\u201d \u201cThe data that will be collected for the atlas, when complete, will provide an entry point for deeper study of cells\u2019 functions and interactions, both within their home tissues and more broadly throughout the body,\u201d said Teichmann, head of cellular genetics at the Sanger Institute, a director of research in the Physics Department at the University of Cambridge, and a senior research fellow of Churchill College, Cambridge. \u201cSuch knowledge will, over time, have a transformative effect on the scientific understanding of human biology and on human health.\u201d Global strategic blueprint The HCA launched in 2016 with a goal as ambitious in scope as the Human Genome Project: to create a reference catalog of all human cells, their proportions, their locations, and the interactions between them. The white paper states that for the first draft of the atlas, the consortium will study and map between 30 and 100 million cells from select organs and tissues, using massively-parallel single-cell RNA sequencing (a suite of genomic techniques capable of identifying gene expression profiles in thousands of individual cells at a time), related technologies to characterize other molecules, and spatial methods to map cells\u2019 locations and interactions. The consortium\u2019s long-term goal is to profile at least 10 billion cells covering all tissues, organs, and systems, representing healthy tissues as well as those affected by particular diseases and conditions. The full atlas will be as diverse as possible, capturing a range of diseases, geographic locations, environments, and age groups. Governance In addition to setting the goals and scope of the atlas\u2019s first draft, the white paper outlines the consortium\u2019s organizational and governance structures, with significant emphasis on scientific diversity and inclusiveness. It also provides a set of guiding principles grounded in ethics, equity, and openness, reflecting the consortium\u2019s scientific grass-roots origins. The HCA is steered and governed by an Organizing Committee (OC), the decision-making body of the HCA. The OC comprises 27 scientists from 10 countries and is currently co-chaired by Aviv Regev (Broad Institute) and Sarah Teichmann (Wellcome Trust Sanger Institute). View the full list of HCA leadership here . \u201cHCA was conceived and initiated by scientists, and it is being governed and run by scientists from 19 institutions across 10 countries,\u201d said Piero Carninci , director of the division of genomic technologies at RIKEN (The Institute of Physical and Chemical Research) in Japan and deputy director of the RIKEN Center for Life Science Technologies. \u201cAlready dozens of scientists from around the world, including various Asian countries, have expressed their interest in participating in and contributing their expertise to HCA studies.\u201d Data from the first one million cells, and the path to ten billion The immune cell expression data announced today will be available in a public online resource by early November, and include single-cell RNA expression profiles of approximately one million cells collected from bone marrow and cord blood from healthy human donors. This expression data  , allowing members of the scientific community to use the information in research. A commitment to open access is one of the core values of the HCA, along with key ethical considerations. Funders Various government and philanthropic organizations around the world have supported HCA and HCA-related scientific activities. Since 2015, the U.S. National Institutes of Health has supported more than $200 million in HCA-related activities, including pilot and foundational projects. Additional supporters include: the Chan-Zuckerberg Initiative, which has provided key support for the HCA\u2019s Data Coordination Platform; The Wellcome Trust, The Manton Foundation, The Kavli Foundation, and others. About the Human Cell Atlas The Human Cell Atlas (HCA) is an international collaborative consortium, which aims to create comprehensive reference maps of all human cells\u2014the fundamental units of life\u2014as a basis for both understanding human health and diagnosing, monitoring, and treating disease. The HCA is a foundational, open resource charting cells, tissues, organs and systems throughout the body. The HCA will impact every aspect of biology and medicine, propelling translational discoveries and applications and ultimately leading to a new era of precision medicine. The HCA is steered and governed by an Organizing Committee, spanning 27 scientists from 10 countries and diverse areas of expertise. The HCA Organizing Committee is currently co-chaired by Dr. Aviv Regev of   Harvard (USA) and Dr. Sarah Teichmann of the Wellcome Trust Sanger Institute (UK). For more information about The Human Cell Atlas, visit https://www.humancellatlas.org .", "highlightText": "", "highlightTitle": "", "language": "english", "external_links": [], "entities": {"persons": [{"name": "teichmann", "sentiment": "none"}, {"name": "sarah teichmann", "sentiment": "none"}, {"name": "aviv regev", "sentiment": "none"}, {"name": "piero carninci", "sentiment": "none"}], "organizations": [{"name": "weizmann institute of science", "sentiment": "none"}, {"name": "institute of physical and chemical research", "sentiment": "none"}, {"name": "broad institute of mit", "sentiment": "none"}, {"name": "physics department", "sentiment": "none"}, {"name": "kavli foundation", "sentiment": "none"}, {"name": "harvard", "sentiment": "none"}, {"name": "manton foundation", "sentiment": "none"}, {"name": "sanger institute", "sentiment": "none"}, {"name": "u.s. national institutes of health", "sentiment": "none"}, {"name": "broad communications  blueprint", "sentiment": "none"}, {"name": "university of cambridge", "sentiment": "none"}, {"name": "klarman cell observatory", "sentiment": "none"}, {"name": "wellcome trust sanger institute", "sentiment": "none"}, {"name": "hca organizing committee", "sentiment": "none"}, {"name": "hca", "sentiment": "none"}, {"name": "riken center for life science technologies", "sentiment": "none"}, {"name": "broad institute", "sentiment": "none"}, {"name": "organizing committee", "sentiment": "none"}, {"name": "churchill college", "sentiment": "none"}, {"name": "chan-zuckerberg initiative", "sentiment": "none"}, {"name": "massachusetts institute of technology", "sentiment": "none"}, {"name": "hca youtube", "sentiment": "none"}, {"name": "riken", "sentiment": "none"}, {"name": "cell circuits program", "sentiment": "none"}, {"name": "wellcome trust", "sentiment": "none"}], "locations": [{"name": "usa", "sentiment": "none"}, {"name": "japan", "sentiment": "none"}, {"name": "uk", "sentiment": "none"}, {"name": "rehovot", "sentiment": "none"}, {"name": "israel", "sentiment": "none"}, {"name": "cambridge", "sentiment": "none"}]}, "rating": null, "crawled": "2017-10-18T17:33:03.004+03:00"}, {"thread": {"uuid": "24e509056e099a9d46107566873a4c2d21d3bd4c", "url": "http://omgili.com/ri/.wHSUbtEfZShuqU8OSon1xB4C1imBQp0uCXKWA0r6sN3TmKqHkxWrhH10Gkh5NSiAi6hWtTW2L6dI.aaPfHNbhyTumAQExAV88kIw0T8UNVnWk0Zm1uErMDUkVXviZuzqj8Y30ZX0xDaqcveKXSiRQ--", "site_full": "www.broadinstitute.org", "site": "broadinstitute.org", "site_section": "https://www.broadinstitute.org/rss.xml", "site_categories": ["health"], "section_title": "Broad Institute", "title": "Researchers extend power of gene editing by developing a new class of DNA base editors", "title_full": "Researchers extend power of gene editing by developing a new class of DNA base editors", "published": "2017-10-25T20:00:00.000+03:00", "replies_count": 0, "participants_count": 1, "site_type": "news", "country": "US", "spam_score": 0.0, "main_image": "", "performance_score": 0, "domain_rank": 45479, "social": {"facebook": {"likes": 0, "comments": 0, "shares": 0}, "gplus": {"shares": 0}, "pinterest": {"shares": 0}, "linkedin": {"shares": 0}, "stumbledupon": {"shares": 0}, "vk": {"shares": 0}}}, "uuid": "24e509056e099a9d46107566873a4c2d21d3bd4c", "url": "http://omgili.com/ri/.wHSUbtEfZShuqU8OSon1xB4C1imBQp0uCXKWA0r6sN3TmKqHkxWrhH10Gkh5NSiAi6hWtTW2L6dI.aaPfHNbhyTumAQExAV88kIw0T8UNVnWk0Zm1uErMDUkVXviZuzqj8Y30ZX0xDaqcveKXSiRQ--", "ord_in_thread": 0, "author": "leah@broadinstitute.org", "published": "2017-10-25T20:00:00.000+03:00", "title": "Researchers extend power of gene editing by developing a new class of DNA base editors", "text": "Researchers extend power of gene editing by developing a new class of DNA base editors Credit : Image courtesy of Susanna M. Hamilton, Broad Communications By Broad Communications \nNew platform holds potential for reversing the most common class of disease-associated DNA point mutations \nScientists at Harvard University and the Broad Institute of MIT and Harvard have developed a new class of genome editing tool. This new \u201cbase editor\u201d can directly repair the type of single-letter changes in the human genome that account for approximately half of human disease-associated point mutations. These mutations are associated with disorders ranging from genetic blindness to sickle-cell anemia to metabolic disorders to cystic fibrosis. \nThe research team, led by David Liu, professor of chemistry and chemical biology at Harvard University, core institute member at the Broad Institute, and a Howard Hughes Medical Institute (HHMI) investigator, developed a molecular machine that can convert the DNA base pair A\u2022T to G\u2022C, without cutting the double helix, with high efficiency and virtually no undesired products. The development is an important addition to the growing suite of genome editing tools. \nThe new system is described in a paper published today in Nature . In addition to Liu, the study was led by Nicole Gaudelli, a postdoctoral fellow in Liu\u2019s lab; Alexis Komor, a former postdoctoral fellow in Liu\u2019s lab who is now an assistant professor at UCSD; graduate student Holly Rees; former graduate students Michael Packer and Ahmed Badran, and former postdoctoral fellow David Bryson. Holly Rees, David Liu, and Nicole Gaudelli. (Credit: Casey Atkins) \nThe new system, dubbed Adenine Base Editor, or ABE, can be programmed to target a specific base pair in a genome using a guide RNA and a modified form of CRISPR-Cas9. It works by rearranging the atoms in a target adenine (A) \u2014 one of the four bases that make up DNA \u2014 to instead resemble guanine (G), and then tricking cells into fixing the other DNA strand to complete the base pair conversion, making the change permanent. As a result, what used to be an A\u2022T base pair becomes a G\u2022C base pair. \nNot only is the system very efficient compared with other genome editing techniques for correcting point mutations, but there are virtually no detectable byproducts such as random insertions, deletions, translocations, or other base-to-base conversions. \nMaking this specific change is important because approximately half of the 32,000 disease-associated point mutations already identified by researchers are a change from G\u2022C to A\u2022T. \n\u201cWe developed a new base editor \u2014 a molecular machine \u2014 that in a programmable, irreversible, efficient, and clean manner can correct these mutations in the genome of living cells,\u201d said Liu, who is also the Richard Merkin Professor and Director of the Merkin Institute of Transformative Technologies in Healthcare at the Broad. \u201cWhen targeted to certain sites in human genomic DNA, this conversion reverses the mutation that is associated with a particular disease.\u201d \nABE joins other base-editing systems pioneered in Liu\u2019s lab, such as BE3 and its improved variant, BE4. Using these base editors, researchers can now correct all the so-called \u201ctransition\u201d mutations \u2014 C to T, T to C, A to G, or G to A \u2014 that together account for almost two-thirds of all disease-causing point mutations, including many that cause serious illnesses for which there are no current treatments. Additional research is needed, Liu notes, to enable ABE to target as much of the genome as possible, as Liu and his students previously achieved through engineering variants of BE3. \nDevelopment of the new base editor began when the team began a year-long effort to evolve a new enzyme that could convert adenine into inosine (I), a nucleotide that behaves similarly to G during DNA or RNA synthesis. The project, led by Gaudelli, ultimately resulted in high-performance, seventh-generation ABEs. \n\u201cThe main challenge for me while developing ABE was overcoming the psychological hurdle of whether or not ABE could go from concept to reality, since the key component of the editor did not exist naturally and had to be evolved in our lab,\u201d said Gaudelli. \u201cIt was important to keep the faith that we could not only dream of such a molecular machine, but also build it.\u201d \nTo demonstrate ABE\u2019s potential, Liu and colleagues first used ABE to directly correct a mutation that causes hereditary hemochromatosis (HHC) in human cells. \nThey also used ABE to install a mutation in human cells that suppresses a disease, recreating the so-called \u201cBritish mutation\u201d found in healthy individuals who would normally develop blood diseases like sickle cell anemia but instead have a mutation that causes fetal hemoglobin genes to remain active after birth, protecting them from the blood diseases. \nWhile the development of ABE is an exciting step forward in base editing, more work remains before base editing can be used to treat patients with genetic diseases, including tests of safety, efficacy, and side effects. \n\u201cCreating a machine that makes the genetic change you need to treat a disease is an important step forward, but it\u2019s only one part of what\u2019s needed to treat a patient,\u201d said Liu. \u201cWe still have to deliver that machine, we have to test its safety, we have to assess its beneficial effects in animals and patients and weigh them against any side effects \u2014 we need to do many more things.\u201d \n\u201cBut having the machine is a good start.\u201d \nThis work was supported by DARPA HR0011-17-2-0049, U.S. National Institutes of Health (NIH) RM1 HG009490, R01 EB022376, and R35 GM118062, and the Howard Hughes Medical Institute. Paper(s) cited: \nGaudelli NM, et al. Programmable base editing of A\u2022T to G\u2022C in genomic DNA without DNA cleavage . Nature. Advance Online Publication, October 25, 2017. DOI: 10.1038/nature24644. IN BROAD VIDEO", "highlightText": "", "highlightTitle": "", "language": "english", "external_links": [], "entities": {"persons": [{"name": "david liu", "sentiment": "none"}, {"name": "nicole gaudelli", "sentiment": "none"}, {"name": "casey atkins", "sentiment": "none"}, {"name": "holly rees", "sentiment": "none"}, {"name": "alexis komor", "sentiment": "none"}, {"name": "richard merkin", "sentiment": "none"}, {"name": "liu", "sentiment": "none"}, {"name": "david bryson", "sentiment": "none"}, {"name": "gaudelli", "sentiment": "none"}, {"name": "michael packer", "sentiment": "none"}, {"name": "susanna m. hamilton", "sentiment": "none"}, {"name": "ahmed badran", "sentiment": "none"}], "organizations": [{"name": "hhc", "sentiment": "none"}, {"name": "howard hughes medical institute", "sentiment": "none"}, {"name": "merkin institute of transformative technologies in healthcare", "sentiment": "none"}, {"name": "broad institute of mit", "sentiment": "none"}, {"name": "broad communications by broad communications", "sentiment": "none"}, {"name": "harvard university", "sentiment": "none"}, {"name": "nih", "sentiment": "none"}, {"name": "broad institute", "sentiment": "none"}, {"name": "harvard", "sentiment": "none"}, {"name": "ucsd", "sentiment": "none"}, {"name": "darpa", "sentiment": "none"}, {"name": "hhmi", "sentiment": "none"}, {"name": "u.s. national institutes of health", "sentiment": "none"}], "locations": []}, "rating": null, "crawled": "2017-10-25T21:21:26.006+03:00"}, {"thread": {"uuid": "205e65f2f396d9651da10f75c0b74660832ebfc0", "url": "http://omgili.com/ri/.wHSUbtEfZShuqU8OSon1xB4C1imBQp0uCXKWA0r6sN3TmKqHkxWrhH10Gkh5NSibu.mvolMWkJRhcDdxycdQSCL8.afvnwiaGi1Ths2Ko8RxncFWkiuII6PUvHyMWKANde8T7ZgrTU-", "site_full": "www.broadinstitute.org", "site": "broadinstitute.org", "site_section": "https://www.broadinstitute.org/rss.xml", "site_categories": ["health"], "section_title": "Broad Institute", "title": "Researchers engineer CRISPR to edit single RNA letters in human cells", "title_full": "Researchers engineer CRISPR to edit single RNA letters in human cells", "published": "2017-10-25T19:55:00.000+03:00", "replies_count": 0, "participants_count": 1, "site_type": "news", "country": "US", "spam_score": 0.0, "main_image": "", "performance_score": 0, "domain_rank": 45479, "social": {"facebook": {"likes": 0, "comments": 0, "shares": 0}, "gplus": {"shares": 0}, "pinterest": {"shares": 0}, "linkedin": {"shares": 0}, "stumbledupon": {"shares": 0}, "vk": {"shares": 0}}}, "uuid": "205e65f2f396d9651da10f75c0b74660832ebfc0", "url": "http://omgili.com/ri/.wHSUbtEfZShuqU8OSon1xB4C1imBQp0uCXKWA0r6sN3TmKqHkxWrhH10Gkh5NSibu.mvolMWkJRhcDdxycdQSCL8.afvnwiaGi1Ths2Ko8RxncFWkiuII6PUvHyMWKANde8T7ZgrTU-", "ord_in_thread": 0, "author": "kzusi@broadinstitute.org", "published": "2017-10-25T19:55:00.000+03:00", "title": "Researchers engineer CRISPR to edit single RNA letters in human cells", "text": "Researchers engineer CRISPR to edit single RNA letters in human cells Credit : Broad Communications, Susanna M. Hamilton By Broad Communications \nNew \u2018REPAIR\u2019 system edits RNA, rather than DNA; has potential to treat diseases without permanently affecting the genome \nThe Broad Institute and MIT scientists who first harnessed CRISPR for mammalian genome editing have engineered a new molecular system for efficiently editing RNA in human cells. RNA editing, which can alter gene products without making changes to the genome, has profound potential as a tool for both research and disease treatment. \nIn a paper published today in Science , senior author Feng Zhang and his team describe the new CRISPR-based system, called RNA Editing for Programmable A to I Replacement, or \u201cREPAIR.\u201d The system can change single RNA nucleotides in mammalian cells in a programmable and precise fashion. REPAIR has the ability to reverse disease-causing mutations at the RNA level, as well as other potential therapeutic and basic science applications. \n\u201cThe ability to correct disease-causing mutations is one of the primary goals of genome editing,\u201d said Zhang, a core institute member at the Broad Institute and investigator at the McGovern Institute for Brain Research at MIT. \u201cSo far, we\u2019ve gotten very good at inactivating genes, but actually recovering lost protein function is much more challenging. This new ability to edit RNA opens up more potential opportunities to recover that function and treat many diseases, in almost any kind of cell.\u201d \nREPAIR has the ability to target individual RNA letters, or nucleosides, switching adenosines to inosines (read as guanosines by the cell). These letters are involved in single-base changes known to regularly cause disease in humans. In human disease, a mutation from G to A is extremely common; these alterations have been implicated in, for example, cases of focal epilepsy, Duchenne muscular dystrophy, and Parkinson\u2019s disease. REPAIR has the ability to reverse the impact of any pathogenic G-to-A mutation regardless of its surrounding nucleotide sequence, with the potential to operate in any cell type. \nUnlike the permanent changes to the genome required for DNA editing, RNA editing offers a safer, more flexible way to make corrections in the cell. \u201cREPAIR can fix mutations without tampering with the genome, and because RNA naturally degrades, it\u2019s a potentially reversible fix,\u201d explained co-first author David Cox, a graduate student in Zhang\u2019s lab. Infographic: What is Cas13? \nTo create REPAIR, the researchers systematically profiled the CRISPR-Cas13 enzyme family for potential \u201ceditor\u201d candidates. (Unlike Cas9, the Cas13 proteins target and cut RNA; see infographic in sidebar). They selected an enzyme from Prevotella bacteria, called PspCas13b, which was the most effective at inactivating RNA. The team engineered a deactivated variant of PspCas13b that still binds to specific stretches of RNA but lacks its \u201cscissor-like\u201d activity, and fused it to a protein called ADAR2, which changes the letters A to I in RNA transcripts. \nIn REPAIR, the deactivated Cas13b enzyme seeks out a target sequence of RNA, and the ADAR2 element performs the base conversion without cutting the transcript or relying on any of the cell\u2019s native machinery. \nThe team further modified the editing system to improve its specificity, reducing detectable off-target edits from 18,385 to only 20 in the whole transcriptome. The upgraded incarnation, REPAIRv2, consistently achieved the desired edit in 20 to 40 percent \u2014 and up to 51 percent \u2014 of a targeted RNA without signs of significant off-target activity. \u201cThe success we had engineering this system is encouraging, and there are clear signs REPAIRv2 can be evolved even further for more robust activity while still maintaining specificity,\u201d said Omar Abudayyeh, co-first author and a graduate student in Zhang\u2019s lab. \nTo demonstrate REPAIR\u2019s therapeutic potential, the team synthesized the pathogenic mutations that cause Fanconi anemia and X-linked nephrogenic diabetes insipidus, introduced them into human cells, and successfully corrected these mutations at the RNA level. To push the therapeutic prospects further, the team plans to improve REPAIRv2\u2019s efficiency and to package it into a delivery system appropriate for introducing REPAIRv2 into specific tissues in animal models. \nThe researchers are also working on additional tools for other types of nucleotide conversions. \u201cThere\u2019s immense natural diversity in these enzymes,\u201d said co-first author Jonathan Gootenberg, a graduate student in both Zhang\u2019s lab and the lab of Broad core institute member Aviv Regev. \u201cWe\u2019re always looking to harness the power of nature to carry out these changes.\u201d \nZhang, along with the Broad Institute and MIT, plan to share the REPAIR system widely. As with earlier CRISPR tools, the groups will make this technology freely available for academic research via the Zhang lab\u2019s page on the plasmid-sharing website Addgene, through which the Zhang lab has already shared reagents more than 42,000 times with researchers at more than 2,200 labs in 61 countries, accelerating research around the world. \nThis research was funded in part by the National Institutes of Health, grants 1R01-HG009761, 1R01-MH110049, and 1DP1-HL141201. Paper(s) cited: \nCox DBT, Gootenberg JS, Abudayyeh OO, et al. RNA editing with CRISPR-Cas13 . Science . Online October 25, 2017. DOI: 10.1126/science.aaq0180 In Broad Video", "highlightText": "", "highlightTitle": "", "language": "english", "external_links": [], "entities": {"persons": [{"name": "omar abudayyeh", "sentiment": "none"}, {"name": "feng zhang", "sentiment": "none"}, {"name": "jonathan gootenberg", "sentiment": "none"}, {"name": "duchenne", "sentiment": "none"}, {"name": "zhang", "sentiment": "none"}, {"name": "david cox", "sentiment": "none"}, {"name": "susanna m. hamilton", "sentiment": "none"}, {"name": "aviv regev", "sentiment": "none"}], "organizations": [{"name": "broad communications", "sentiment": "negative"}, {"name": "mcgovern institute for brain research", "sentiment": "none"}, {"name": "cox dbt", "sentiment": "none"}, {"name": "mit", "sentiment": "none"}, {"name": "gootenberg js", "sentiment": "none"}, {"name": "national institutes of health", "sentiment": "none"}, {"name": "abudayyeh oo", "sentiment": "none"}, {"name": "broad institute", "sentiment": "none"}], "locations": [{"name": "prevotella", "sentiment": "none"}]}, "rating": null, "crawled": "2017-10-25T21:21:29.009+03:00"}, {"thread": {"uuid": "d254b0001704d507b6ee990e5514b1efaaa921e8", "url": "http://omgili.com/ri/.wHSUbtEfZShuqU8OSon1xB4C1imBQp0uCXKWA0r6sNf7iK_vrex8uy40JGDIB.IxuwzZ.YTDBO.u6Fa8nbVOzRz1Fj.dZ43PfT6HyzGR4ID4o24NWSG7jOYjs8bEmxM", "site_full": "www.broadinstitute.org", "site": "broadinstitute.org", "site_section": "https://www.broadinstitute.org/rss.xml", "site_categories": ["health"], "section_title": "Broad Institute", "title": "Editing false positives from cancer dependency maps drawn with CRISPR", "title_full": "Editing false positives from cancer dependency maps drawn with CRISPR", "published": "2017-10-30T18:01:00.000+02:00", "replies_count": 0, "participants_count": 1, "site_type": "news", "country": "US", "spam_score": 0.0, "main_image": "", "performance_score": 0, "domain_rank": 45479, "social": {"facebook": {"likes": 0, "comments": 0, "shares": 0}, "gplus": {"shares": 0}, "pinterest": {"shares": 0}, "linkedin": {"shares": 0}, "stumbledupon": {"shares": 0}, "vk": {"shares": 0}}}, "uuid": "d254b0001704d507b6ee990e5514b1efaaa921e8", "url": "http://omgili.com/ri/.wHSUbtEfZShuqU8OSon1xB4C1imBQp0uCXKWA0r6sNf7iK_vrex8uy40JGDIB.IxuwzZ.YTDBO.u6Fa8nbVOzRz1Fj.dZ43PfT6HyzGR4ID4o24NWSG7jOYjs8bEmxM", "ord_in_thread": 0, "author": "tulrich@broadinstitute.org", "published": "2017-10-30T18:01:00.000+02:00", "title": "Editing false positives from cancer dependency maps drawn with CRISPR", "text": "News / 10.30.17 Editing false positives from cancer dependency maps drawn with CRISPR Credit : Lauren Solomon, Broad Communications. Adapted from Meyers RM, Bryan JG, et al. Nature Genetics 2017. By Tom Ulrich \nThe Broad Cancer Dependency Map team adds CRISPR-based data from 342 cancer cell lines to their growing catalog of genetic dependencies in cancer, and a new method for ensuring that data's accuracy. \nGenome-scale CRISPR-based knockout screens are powerful tools for pinpointing cells' genetic dependencies \u2014 that is, genes that cells require for their survival and/or proliferation. However, such CRISPR screens are sensitive to a phenomenon called the copy number effect , where genes that have been repeatedly duplicated within a cell (as commonly happens in cancer cells) can be flagged as essential regardless of whether they are or not. \nTo limit such false-positive hits, the Broad Institute's Cancer Dependency Map project \u2014 a joint effort bringing together researchers from the Broad Cancer Program \u2019s Project Achilles and Cancer Data Science teams, the institute's Genetic Perturbation Platform , and other Broad groups \u2014 has developed CERES , a computational method that corrects pooled CRISPR screen data for the copy number effect and provides an unbiased view of cancer cells' genetic dependencies. \nAs they revealed in Nature Genetics , the team benchmarked CERES against genome-scale CRISPR-Cas9 data from 342 cancer cell lines (the largest CRISPR knockout dataset generated in cancer lines to date) curated by the Broad-Novartis Cancer Cell Line Encyclopedia (CCLE) . The method greatly reduced false-positive readouts in the data, pinpointing known dependencies (e.g., KRAS mutations) and allowing new dependencies to become apparent. \nThe new dependency data complement the Dependency Map team's ongoing efforts to use functional genomic technologies like CRISPR and RNA interference (RNAi) to locate vulnerabilities that arise within cancer cells as they compensate for the loss of critical genes due to mutations or expression changes. Earlier this year the team announced that they had cataloged 769 strong genetic dependencies across 501 CCLE-curated cell lines using genome-scale RNAi screens \u2014 the fruits of a nearly 10-year effort . \nCERES joins two prior computational methods the team has developed to filter false-positive results from functional genomic screen data: ATARiS and DEMETER , both of which weed out so-called seed effects that commonly plague RNAi data. \nSupport for this study was provided by the National Cancer Institute (grant numbers U01CA176058, U01CA199253, and P01CA154303) and the Slim Initiative for Genomic Medicine in the Americas , a project funded by the Carlos Slim Foundation. Paper(s) cited:", "highlightText": "", "highlightTitle": "", "language": "english", "external_links": [], "entities": {"persons": [{"name": "laure", "sentiment": "negative"}, {"name": "bryan jg", "sentiment": "none"}, {"name": "tom ulrich", "sentiment": "none"}, {"name": "solomon", "sentiment": "none"}], "organizations": [{"name": "genomic medicine", "sentiment": "none"}, {"name": "meyers rm", "sentiment": "none"}, {"name": "nature genetics", "sentiment": "none"}, {"name": "demeter", "sentiment": "none"}, {"name": "broad institute", "sentiment": "none"}, {"name": "ceres", "sentiment": "none"}, {"name": "broad communications", "sentiment": "none"}, {"name": "broad cancer program", "sentiment": "none"}, {"name": "cancer data science", "sentiment": "none"}, {"name": "national cancer institute", "sentiment": "none"}, {"name": "kras", "sentiment": "none"}, {"name": "carlos slim foundation", "sentiment": "none"}, {"name": "genetic perturbation platform", "sentiment": "none"}], "locations": [{"name": "americas", "sentiment": "none"}, {"name": "ceres", "sentiment": "none"}]}, "rating": null, "crawled": "2017-10-30T19:39:26.009+02:00"}], "totalResults": 13, "moreResultsAvailable": 0, "next": "/filterWebContent?token=1eee5ef1-4d51-497e-9e88-ed86353bcda9&format=json&ts=1509385166009&q=language%3Aenglish+site%3Abroadinstitute.org&sort=crawled", "requestsLeft": 602}